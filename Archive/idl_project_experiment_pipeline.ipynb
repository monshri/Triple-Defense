{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "idl_project_experiment_pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "emCbgIPQ5yA5",
        "vEzaTmhp7qFg",
        "SH-xmYJL8n14",
        "Ng7Xe9Zq8rai",
        "f-w5HNiC8vDY",
        "gP_Gxq-2jc-9",
        "YoYiKeGCjfDR",
        "LyMeGON8BFNL"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "36c702f40e384a74a55157ca8f620ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ee3f100b842e4a2cbe480c4263c582b8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a54b7c1fe1d943f885bf2dfeed804d68",
              "IPY_MODEL_23b2af10d460436eae2df148ddae7b56"
            ]
          }
        },
        "ee3f100b842e4a2cbe480c4263c582b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a54b7c1fe1d943f885bf2dfeed804d68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c2bfe370fb7a4f5fb9358265d35fa296",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8400e9c2ed724221831fa4bd7ec7a2ab"
          }
        },
        "23b2af10d460436eae2df148ddae7b56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_257af78b3bb945ed9ea020a22d889552",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:19&lt;00:00, 33421396.64it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_db16dcc43cb843dbbf8a96df0b652921"
          }
        },
        "c2bfe370fb7a4f5fb9358265d35fa296": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8400e9c2ed724221831fa4bd7ec7a2ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "257af78b3bb945ed9ea020a22d889552": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "db16dcc43cb843dbbf8a96df0b652921": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaichengDING/Triple-Defense/blob/main/idl_project_experiment_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8idp0UC0Oj6"
      },
      "source": [
        "# Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ESeViSYxQfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "154c2879-53d7-4f17-f9e3-a726e27ccf33"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgPpHa2d0Rt4"
      },
      "source": [
        "# Install ART\r\n",
        "ART is now updated to version 1.5.0, however we observed some incompatibility issue with our ensemble classifier, thus we decide to stick to version 1.4.3 and will fix it later if possible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzKNCLpGws5x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "028e00d1-3f1e-4537-b652-f0bfdf038811"
      },
      "source": [
        "!pip install adversarial-robustness-toolbox==1.4.3"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting adversarial-robustness-toolbox==1.4.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/aa/1136628240b23de5c311aa1595d327f3908296a71f72093370a0459b8f0b/adversarial_robustness_toolbox-1.4.3-py3-none-any.whl (765kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 768kB 13.6MB/s \n",
            "\u001b[?25hCollecting mypy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e2/cb/cf5530d063e7e703e2fbec677bfba633de6e70fe44bc323deeaa27f273b8/mypy-0.790-cp36-cp36m-manylinux1_x86_64.whl (21.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21.0MB 99.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox==1.4.3) (1.15.0)\n",
            "Requirement already satisfied: resampy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox==1.4.3) (0.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox==1.4.3) (3.2.2)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox==1.4.3) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox==1.4.3) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox==1.4.3) (1.18.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox==1.4.3) (7.0.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox==1.4.3) (0.10.2)\n",
            "Collecting cma\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/c0/0a1c41f7cad0a51e07991cf86423d0e6651d035f1fe7dcff48e8858848f2/cma-3.0.3-py2.py3-none-any.whl (230kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 235kB 70.5MB/s \n",
            "\u001b[?25hCollecting pydub\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/d1/fbfa79371a8cd9bb15c2e3c480d7e6e340ed5cc55005174e16f48418333a/pydub-0.24.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox==1.4.3) (50.3.2)\n",
            "Collecting scikit-learn==0.22.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/7f/366dcba1ba076a88a50bea732dbc033c0c5bbf7876010e6edc67948579d5/scikit_learn-0.22.2-cp36-cp36m-manylinux1_x86_64.whl (7.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.1MB 26.5MB/s \n",
            "\u001b[?25hCollecting ffmpeg-python\n",
            "  Downloading https://files.pythonhosted.org/packages/d7/0c/56be52741f75bad4dc6555991fabd2e07b432d333da82c11ad701123888a/ffmpeg_python-0.2.0-py3-none-any.whl\n",
            "Collecting typed-ast<1.5.0,>=1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/ed/5459080d95eb87a02fe860d447197be63b6e2b5e9ff73c2b0a85622994f4/typed_ast-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (737kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 747kB 60.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.6/dist-packages (from mypy->adversarial-robustness-toolbox==1.4.3) (3.7.4.3)\n",
            "Collecting mypy-extensions<0.5.0,>=0.4.3\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/eb/975c7c080f3223a5cdaff09612f3a5221e4ba534f7039db34c35d95fa6a5/mypy_extensions-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numba>=0.32 in /usr/local/lib/python3.6/dist-packages (from resampy->adversarial-robustness-toolbox==1.4.3) (0.48.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox==1.4.3) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox==1.4.3) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox==1.4.3) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox==1.4.3) (1.3.1)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.6/dist-packages (from statsmodels->adversarial-robustness-toolbox==1.4.3) (1.1.5)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels->adversarial-robustness-toolbox==1.4.3) (0.5.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.22.2->adversarial-robustness-toolbox==1.4.3) (0.17.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from ffmpeg-python->adversarial-robustness-toolbox==1.4.3) (0.16.0)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.32->resampy->adversarial-robustness-toolbox==1.4.3) (0.31.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->statsmodels->adversarial-robustness-toolbox==1.4.3) (2018.9)\n",
            "Installing collected packages: typed-ast, mypy-extensions, mypy, cma, pydub, scikit-learn, ffmpeg-python, adversarial-robustness-toolbox\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed adversarial-robustness-toolbox-1.4.3 cma-3.0.3 ffmpeg-python-0.2.0 mypy-0.790 mypy-extensions-0.4.3 pydub-0.24.1 scikit-learn-0.22.2 typed-ast-1.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HL8u7HvJ0Xka"
      },
      "source": [
        "# Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SqUPdAKkDIn"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import PIL\n",
        "\n",
        "import sys\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "\n",
        "from torch.utils import data\n",
        "\n",
        "from art.attacks.evasion import FastGradientMethod\n",
        "from art.attacks.evasion import ProjectedGradientDescentPyTorch\n",
        "from art.estimators.classification import PyTorchClassifier\n",
        "\n",
        "from art.estimators.classification import EnsembleClassifier\n",
        "from typing import List, Optional, Union, TYPE_CHECKING\n",
        "from art.estimators.classification.classifier import ClassifierNeuralNetwork\n",
        "from scipy.special import softmax\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import logging\n",
        "import datetime\n",
        "import random\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcOnXEFW1m4K"
      },
      "source": [
        "# Model Definition\r\n",
        "The architecture of our candidate model is ShuffleNet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfyaOczXoRqQ"
      },
      "source": [
        "class ShuffleNet(nn.Module):\n",
        "    def __init__(self, nb_classes=10):\n",
        "        super(ShuffleNet, self).__init__()\n",
        "        self.shuffle = models.shufflenet_v2_x2_0()\n",
        "        self.linear = nn.Linear(1000, nb_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.shuffle(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlygMiHF0iSB"
      },
      "source": [
        "# Logging Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXX4443Y16Ul"
      },
      "source": [
        "# configure logging\n",
        "logger = logging.getLogger(\"\")\n",
        "\n",
        "# reset handler\n",
        "for handler in logging.root.handlers[:]:\n",
        "  logging.root.removeHandler(handler)\n",
        "\n",
        "# set handler\n",
        "stream_hdlr = logging.StreamHandler()\n",
        "# logging on colab\n",
        "file_hdlr = logging.FileHandler('/content/gdrive/My Drive/IDL_Project/logs/log_{}.log'.format(datetime.datetime.now()))\n",
        "\n",
        "formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
        "stream_hdlr.setFormatter(formatter)\n",
        "file_hdlr.setFormatter(formatter)\n",
        "\n",
        "logger.addHandler(stream_hdlr)\n",
        "logger.addHandler(file_hdlr)\n",
        "\n",
        "logger.setLevel(logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFiB-FbgT9sk"
      },
      "source": [
        "# Get Test Examples\r\n",
        "We create this dataset class so that we can get a subset from the original CIFAR-10 dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gk68nikXxa4G"
      },
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, X, Y, transform=None):\n",
        "    self.X = X\n",
        "    self.Y = Y\n",
        "    self.transform = transform\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.Y)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    if self.transform is None:\n",
        "      return torch.from_numpy(self.X[idx]), torch.tensor(self.Y[idx]).long()\n",
        "    else:\n",
        "      return self.transform(self.X[idx]), torch.tensor(self.Y[idx]).long()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XV2pPKKzeESx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82,
          "referenced_widgets": [
            "36c702f40e384a74a55157ca8f620ccf",
            "ee3f100b842e4a2cbe480c4263c582b8",
            "a54b7c1fe1d943f885bf2dfeed804d68",
            "23b2af10d460436eae2df148ddae7b56",
            "c2bfe370fb7a4f5fb9358265d35fa296",
            "8400e9c2ed724221831fa4bd7ec7a2ab",
            "257af78b3bb945ed9ea020a22d889552",
            "db16dcc43cb843dbbf8a96df0b652921"
          ]
        },
        "outputId": "bc9ce327-6638-441b-b71e-5bf0ac266bbf"
      },
      "source": [
        "test_batchsize = 200\n",
        "num_workers = 4\n",
        "nb_classes = 10\n",
        "img_size = 224\n",
        "subset_size = 1000\n",
        "\n",
        "test_transform = transforms.Compose([transforms.ToPILImage(),\n",
        "                                     transforms.Resize(size=img_size),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.Normalize((0, 0, 0), (1, 1, 1))])\n",
        "\n",
        "testset= torchvision.datasets.CIFAR10(root='./data', train=False, download=True)\n",
        "testset_data = testset.data[0:subset_size]\n",
        "testset_labels = testset.targets[0:subset_size]\n",
        "\n",
        "testset_sub = MyDataset(testset_data, testset_labels, transform=test_transform)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset_sub, batch_size=test_batchsize, shuffle=False, num_workers=num_workers, drop_last=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36c702f40e384a74a55157ca8f620ccf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOPbwP7FTWEY"
      },
      "source": [
        "# Load Saved Models and Create Classifier List (Skip for now)\n",
        "All saved models will be loaded into `model_dict`. Models with seed number smaller than 200 belong to `ShuffleNet` class, and models with seed number greater than 200 belong to `ShuffleNetV2` class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUiLYb1EeNtS"
      },
      "source": [
        "# # models trained with 0.1 Gaussian noise\n",
        "# model_names = ['ShuffleNet_1',\n",
        "#                'ShuffleNet_2',\n",
        "#                'ShuffleNet_3',\n",
        "#                'ShuffleNet_4',\n",
        "#                'ShuffleNet_5',\n",
        "#                'ShuffleNet_6',\n",
        "#                'ShuffleNet_7',\n",
        "#                'ShuffleNet_8',\n",
        "#                'ShuffleNet_31',\n",
        "#                'ShuffleNet_32',\n",
        "#                'ShuffleNet_33',\n",
        "#                'ShuffleNet_34',\n",
        "#                'ShuffleNet_35']\n",
        "\n",
        "# # models trained with 0.1 Uniform noise \n",
        "# model_names = ['Shufflenet0_u_0.1',\n",
        "#                'Shufflenet1_u_0.1',\n",
        "#                'Shufflenet2_u_0.1',\n",
        "#                'Shufflenet3_u_0.1',\n",
        "#                'Shufflenet4_u_0.1',\n",
        "#                'Shufflenet5_u_0.1',\n",
        "#                'Shufflenet6_u_0.1',\n",
        "#                'Shufflenet7_u_0.1',\n",
        "#                'Shufflenet8_u_0.1',\n",
        "#                'Shufflenet9_u_0.1']\n",
        "\n",
        "# model_dict = {}\n",
        "\n",
        "# for model_name in model_names:\n",
        "#   model = ShuffleNet()\n",
        "#   model_data = torch.load('/content/gdrive/My Drive/IDL_Project/modelS/{}'.format(model_name), map_location=torch.device('cpu'))\n",
        "#   model.load_state_dict(model_data['model_state_dict'])\n",
        "#   model = model.to(device)\n",
        "#   model_dict[model_name] = model\n",
        "\n",
        "# logging.info(\"Total number of models: {}\".format(len(model_names)))\n",
        "\n",
        "# nb_classes = 10\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# classifier_list = []\n",
        "# for model_name in model_dict:\n",
        "#   classifier_list.append(PyTorchClassifier(\n",
        "#     model=model_dict[model_name],\n",
        "#     clip_values=(0, 1),\n",
        "#     loss=criterion,\n",
        "#     input_shape=(3, img_size, img_size),\n",
        "#     nb_classes=nb_classes,\n",
        "# ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inhJeBV-9ic0"
      },
      "source": [
        "# MyEnsembleClassifier\n",
        "Inherited from `EnsembleClassifier` with `predict`, `loss_gradient` and `loss_gradient_framework` overwritten\n",
        "\n",
        "Some updates: \n",
        "*   add support of Uniform noise injection\n",
        "*   add support of abstain\n",
        "*   save model indices used in `predict`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ratuA8nTIKyu"
      },
      "source": [
        "class MyEnsembleClassifier(EnsembleClassifier):\n",
        "    def __init__(\n",
        "        self,\n",
        "        classifiers: List[ClassifierNeuralNetwork],\n",
        "        device,\n",
        "        infer_noise,\n",
        "        infer_noise_type,\n",
        "        num_selected_models,\n",
        "        classifier_weights: Union[list, np.ndarray, None] = None,\n",
        "        channels_first: bool = False,\n",
        "        clip_values: Optional[\"CLIP_VALUES_TYPE\"] = None,\n",
        "        preprocessing_defences: Union[\"Preprocessor\", List[\"Preprocessor\"], None] = None,\n",
        "        postprocessing_defences: Union[\"Postprocessor\", List[\"Postprocessor\"], None] = None,\n",
        "        preprocessing: \"PREPROCESSING_TYPE\" = (0, 1),\n",
        "    ) -> None:\n",
        "      super().__init__(\n",
        "          classifiers=classifiers,\n",
        "          classifier_weights=classifier_weights,\n",
        "          channels_first=channels_first,\n",
        "          clip_values=clip_values,\n",
        "          preprocessing_defences=preprocessing_defences,\n",
        "          postprocessing_defences=postprocessing_defences,\n",
        "          preprocessing=preprocessing\n",
        "      )\n",
        "      self.device = device\n",
        "      self.infer_noise = infer_noise\n",
        "      self.infer_noise_type = infer_noise_type\n",
        "      self.num_models = len(classifiers)\n",
        "      self.num_selected_models = num_selected_models\n",
        "      self.indices = None\n",
        "\n",
        "    def predict(self, x: np.ndarray, batch_size: int = 128, raw: bool = False, **kwargs) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Perform prediction for a batch of inputs. Predictions from classifiers should only be aggregated if they all\n",
        "        have the same type of output (e.g., probabilities). Otherwise, use `raw=True` to get predictions from all\n",
        "        models without aggregation. The same option should be used for logits output, as logits are not comparable\n",
        "        between models and should not be aggregated.\n",
        "        :param x: Test set.\n",
        "        :param batch_size: Size of batches.\n",
        "        :param raw: Return the individual classifier raw outputs (not aggregated).\n",
        "        :return: Array of predictions of shape `(nb_inputs, nb_classes)`, or of shape\n",
        "                 `(nb_classifiers, nb_inputs, nb_classes)` if `raw=True`.\n",
        "        \"\"\"\n",
        "\n",
        "        indices = np.random.choice(self.num_models, self.num_selected_models, replace=True)\n",
        "        self.indices = indices # save in the attribute and will use in loss gradient computation\n",
        "\n",
        "        if self.infer_noise_type == 'uniform':\n",
        "          noise_list = [(np.random.rand(*x.shape) * 2.0 - 1.0) * self.infer_noise for i in indices]\n",
        "        else:\n",
        "          noise_list = [np.random.randn(*x.shape) * self.infer_noise for i in indices]\n",
        "\n",
        "        preds = []\n",
        "        for iidx, i in enumerate(indices):\n",
        "          preds.append(softmax(self._classifiers[i].predict(np.float32(x + noise_list[iidx])), axis=1))\n",
        "        preds = np.array(preds)\n",
        "\n",
        "\n",
        "        del indices\n",
        "        del noise_list\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        if raw:\n",
        "            return preds\n",
        "\n",
        "        preds_classes = np.argmax(preds, axis=2)\n",
        "        row, col = preds_classes.shape\n",
        "\n",
        "        majority_vote = np.array(\n",
        "            [\n",
        "             np.bincount(preds_classes[:,c]).argmax()\n",
        "             for c in range(col)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # CHECK FOR CONDITION TO ABSTAIN       \n",
        "        n_abstained = 0 \n",
        "        alpha = 0.0001\n",
        "        for c in range(col):\n",
        "          # FIND THE TOP TWO CLASS WITH HIGHEST PROBABILITY\n",
        "          temp =  np.flip(np.sort(np.bincount(preds_classes[:,c])/np.sum(preds_classes[:,c])))\n",
        "          # FIND IF THE CLASS PROBABILITY OF TOP TWO CLASSES ARE CLOSE, THEN ABSTAIN\n",
        "          # ALPHA WILL VARY ACCORDINGLY\n",
        "          if (len(temp)>1):\n",
        "            if np.isclose(temp[0],temp[1],atol=alpha):\n",
        "              n_abstained+=1\n",
        "\n",
        "\n",
        "        mask = preds_classes == majority_vote\n",
        "        del majority_vote\n",
        "\n",
        "        mask = np.repeat(np.expand_dims(mask, axis=2), repeats=10, axis=2)\n",
        "\n",
        "        # Aggregate predictions only at probabilities level, as logits are not comparable between models\n",
        "        var_z = np.sum(mask * preds, axis=0) / np.sum(mask, axis=0) # take mean (check sum to 1)\n",
        "        del mask\n",
        "        del preds\n",
        "\n",
        "        # Apply postprocessing\n",
        "        predictions = self._apply_postprocessing(preds=var_z, fit=False)\n",
        "        del var_z\n",
        "        \n",
        "        if n_abstained > 0:\n",
        "            logger.info(\"%s prediction(s) abstained.\", n_abstained)\n",
        "\n",
        "        return predictions\n",
        "\n",
        "\n",
        "    def loss_gradient(self, x: np.ndarray, y: np.ndarray, raw: bool = False, **kwargs) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Compute the gradient of the loss function w.r.t. `x`.\n",
        "        :param x: Sample input with shape as expected by the model.\n",
        "        :param y: Target values (class labels) one-hot-encoded of shape (nb_samples, nb_classes) or indices of shape\n",
        "                  (nb_samples,).\n",
        "        :param raw: Return the individual classifier raw outputs (not aggregated).\n",
        "        :return: Array of gradients of the same shape as `x`. If `raw=True`, shape becomes `[nb_classifiers, x.shape]`.\n",
        "        \"\"\"\n",
        "\n",
        "        indices = self.indices\n",
        "\n",
        "        if self.infer_noise_type == 'uniform':\n",
        "          noise_list = [(np.random.rand(*x.shape) * 2.0 - 1.0) * self.infer_noise for i in indices]\n",
        "        else:\n",
        "          noise_list = [np.random.randn(*x.shape) * self.infer_noise for i in indices]\n",
        "        \n",
        "                \n",
        "        grads = np.array(\n",
        "            [\n",
        "                self._classifiers[i].loss_gradient(np.float32(x + noise_list[iidx]), y)\n",
        "                for iidx, i in enumerate(indices)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "        del indices\n",
        "        del noise_list\n",
        "\n",
        "        if raw:\n",
        "            return grads\n",
        "\n",
        "        return np.sum(grads, axis=0)\n",
        "\n",
        "    def loss_gradient_framework(self, x: \"torch.Tensor\", y: \"torch.Tensor\", **kwargs) -> \"torch.Tensor\":\n",
        "        \"\"\"\n",
        "        Compute the gradient of the loss function w.r.t. `x`.\n",
        "        :param x: Sample input with shape as expected by the model.\n",
        "        :param y: Target values (class labels) one-hot-encoded of shape (nb_samples, nb_classes) or indices of shape\n",
        "                  (nb_samples,).\n",
        "        :param raw: Return the individual classifier raw outputs (not aggregated).\n",
        "        :return: Array of gradients of the same shape as `x`. If `raw=True`, shape becomes `[nb_classifiers, x.shape]`.\n",
        "        \"\"\"\n",
        "\n",
        "        indices = self.indices\n",
        "\n",
        "        if self.infer_noise_type == 'uniform':\n",
        "          noise_list = [((torch.rand(x.size()) * 2.0 - 1.0) * self.infer_noise).to(device) for i in indices]\n",
        "        else:\n",
        "          noise_list = [(torch.randn(x.size()) * self.infer_noise).to(device) for i in indices]\n",
        "\n",
        "        # gradient shape: batch_size, 3, 224, 224\n",
        "        accumulator = torch.zeros(test_batchsize, 3, img_size, img_size)\n",
        "        for iidx, i in enumerate(indices):\n",
        "          accumulator += self._classifiers[i].loss_gradient_framework(x + noise_list[iidx], y).cpu()\n",
        "        \n",
        "        torch.cuda.empty_cache()\n",
        "        del indices\n",
        "        del noise_list\n",
        "\n",
        "        return accumulator.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80wKHjAJV9EF"
      },
      "source": [
        "# Experiment Settings\n",
        "### common settings:\n",
        "*   inference noise: 0.1\n",
        "*   eps: 0.5\n",
        "*   eps step: 0.4\n",
        "*   max iter: 20\n",
        "*   L2 norm\n",
        "*   number of samplings: 50\n",
        "\n",
        "### to experiment:\n",
        "1. Total number of candidate models in the ensemble: 1 (randomized smoothing)\n",
        "2. Total number of candidate models in the ensemble: 5\n",
        "3. Total number of candidate models in the ensemble: 9\n",
        "4. Total number of candidate models in the ensemble: 13"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qgPgn2hXwzB"
      },
      "source": [
        "# Run this code block to load common variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ge6pmhN3X51_"
      },
      "source": [
        "# # L2 norm attack settings\n",
        "# infer_noise = 0.1\n",
        "# eps = 0.5\n",
        "# eps_step = 0.4\n",
        "# max_iter = 20\n",
        "# norm = 2\n",
        "\n",
        "# Linf norm attack settings\n",
        "infer_noise = 0.1\n",
        "eps = 0.03\n",
        "eps_step = 0.02\n",
        "max_iter = 20\n",
        "norm = np.inf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ2kzTjNYcg4"
      },
      "source": [
        "# Experiment 1 (Shivani)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzefdlNUYbx5"
      },
      "source": [
        "model_names = ['ShuffleNet_1']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oqPQe7LYyx8"
      },
      "source": [
        "# Experiment 2 (Kriti)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RX-Ey7FZFld"
      },
      "source": [
        "model_names = ['ShuffleNet_1',\n",
        "               'ShuffleNet_2',\n",
        "               'ShuffleNet_3',\n",
        "               'ShuffleNet_4',\n",
        "               'ShuffleNet_5']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z__h3gZpY1AS"
      },
      "source": [
        "# Experiment 3 (Shriti)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SphoToOzZHdy"
      },
      "source": [
        "model_names = ['ShuffleNet_1',\n",
        "               'ShuffleNet_2',\n",
        "               'ShuffleNet_3',\n",
        "               'ShuffleNet_4',\n",
        "               'ShuffleNet_5',\n",
        "               'ShuffleNet_6',\n",
        "               'ShuffleNet_7',\n",
        "               'ShuffleNet_8',\n",
        "               'ShuffleNet_31']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nF-zmm6WY3XP"
      },
      "source": [
        "# Experiment 4 (Kaicheng)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuSizTHpZIbN"
      },
      "source": [
        "# model_names = ['ShuffleNet_1',\n",
        "#                'ShuffleNet_2',\n",
        "#                'ShuffleNet_3',\n",
        "#                'ShuffleNet_4',\n",
        "#                'ShuffleNet_5',\n",
        "#                'ShuffleNet_6',\n",
        "#                'ShuffleNet_7',\n",
        "#                'ShuffleNet_8',\n",
        "#                'ShuffleNet_31',\n",
        "#                'ShuffleNet_32',\n",
        "#                'ShuffleNet_33',\n",
        "#                'ShuffleNet_34',\n",
        "#                'ShuffleNet_35']\n",
        "\n",
        "model_names = ['Shufflenet0_u_0.1',\n",
        "               'Shufflenet1_u_0.1',\n",
        "               'Shufflenet2_u_0.1',\n",
        "               'Shufflenet3_u_0.1',\n",
        "               'Shufflenet4_u_0.1',\n",
        "               'Shufflenet5_u_0.1',\n",
        "               'Shufflenet6_u_0.1',\n",
        "               'Shufflenet7_u_0.1',\n",
        "               'Shufflenet8_u_0.1',\n",
        "               'Shufflenet9_u_0.1']\n",
        "\n",
        "infer_noise_type = 'uniform'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D7HuN4sY5cz"
      },
      "source": [
        "# Load models and create `classifier_list`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TVPQL9ci-WK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83725d2a-356b-45d1-ab21-a9405cd52eee"
      },
      "source": [
        "model_dict = {}\n",
        "nb_classes = 10\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "classifier_list = []\n",
        "\n",
        "for model_name in model_names:\n",
        "  model = ShuffleNet()\n",
        "  model_data = torch.load('/content/gdrive/My Drive/IDL_Project/modelS/{}'.format(model_name), map_location=torch.device('cpu'))\n",
        "  model.load_state_dict(model_data['model_state_dict'])\n",
        "  model = model.to(device)\n",
        "  model_dict[model_name] = model\n",
        "\n",
        "logging.info(\"Total number of models: {}\".format(len(model_names)))\n",
        "\n",
        "for model_name in model_dict:\n",
        "  classifier_list.append(PyTorchClassifier(\n",
        "    model=model_dict[model_name],\n",
        "    clip_values=(0, 1),\n",
        "    loss=criterion,\n",
        "    input_shape=(3, img_size, img_size),\n",
        "    nb_classes=nb_classes,\n",
        "))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-11 07:58:01,623 INFO Inferred 1 hidden layers on PyTorch classifier.\n",
            "2020-12-11 07:58:01,630 INFO Inferred 1 hidden layers on PyTorch classifier.\n",
            "2020-12-11 07:58:01,635 INFO Inferred 1 hidden layers on PyTorch classifier.\n",
            "2020-12-11 07:58:01,640 INFO Inferred 1 hidden layers on PyTorch classifier.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jiin82Cpi2ia"
      },
      "source": [
        "# Change number of samplings here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ekgfiiQin9d"
      },
      "source": [
        "num_selected_models = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKU4Y8C2jZoh"
      },
      "source": [
        "# Kick off experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmA8Hs__Y9Zf"
      },
      "source": [
        "# create ensemble classifier\n",
        "my_ensemble_classifier = MyEnsembleClassifier(classifier_list,\n",
        "                                              device, \n",
        "                                              infer_noise=infer_noise,\n",
        "                                              infer_noise_type=infer_noise_type,\n",
        "                                              num_selected_models=num_selected_models,\n",
        "                                              clip_values=[0., 1.], \n",
        "                                              channels_first=True)\n",
        "\n",
        "# create attack object\n",
        "attack = ProjectedGradientDescentPyTorch(my_ensemble_classifier, \n",
        "                                         eps=eps, \n",
        "                                         eps_step=eps_step, \n",
        "                                         norm=norm, \n",
        "                                         max_iter=max_iter, \n",
        "                                         batch_size=test_batchsize)\n",
        "\n",
        "# kick off experiment\n",
        "Acc_adv = []\n",
        "Acc_nat = []\n",
        "for batch_idx, (X, Y) in enumerate(testloader):\n",
        "  x_test = X.numpy()\n",
        "  y_test = Y.numpy()\n",
        "  predictions_nat = my_ensemble_classifier.predict(x_test)\n",
        "  accuracy_nat = np.sum(np.argmax(predictions_nat, axis=1) == y_test) / len(y_test)\n",
        "  Acc_nat.append(accuracy_nat)\n",
        "\n",
        "  x_test_adv = attack.generate(torch.from_numpy(x_test), torch.from_numpy(y_test))\n",
        "  predictions_adv = my_ensemble_classifier.predict(x_test_adv)\n",
        "  accuracy_adv = np.sum(np.argmax(predictions_adv, axis=1) == y_test) / len(y_test)\n",
        "  Acc_adv.append(accuracy_adv)\n",
        "\n",
        "  logging.info('accuracy (adversarial): {}'.format(accuracy_adv))\n",
        "  logging.info('accuracy (natural): {}'.format(accuracy_nat))\n",
        "    \n",
        "\n",
        "# saving the dataframe \n",
        "Acc_adv = np.asanyarray(Acc_adv)\n",
        "Acc_nat = np.asanyarray(Acc_nat)\n",
        "res = {'AccADV': Acc_adv, 'AccNAT': Acc_nat} \n",
        "df = pd.DataFrame(res)\n",
        "df.to_csv('./gdrive/My Drive/IDL_Project/results/result_{}models_{}samples.csv'.format(len(model_names), num_selected_models),index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdUjTkdWBdgh"
      },
      "source": [
        "# **The rest parts of the notebook was regarding previous work. Discard them for now.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emCbgIPQ5yA5"
      },
      "source": [
        "# Experiment Settings (**deprecated**)\n",
        "Refer to [this google doc](https://docs.google.com/document/d/1VaS5THALdudd_63Zv7ZR2u8rj8r8iDF6xgXzzLHXR8w/edit)\n",
        "\n",
        "1.   `num_selected_models`=15, `infer_noise`=[0.0025, 0.005, 0.01, 0.05, 0.08, 0.1], `eps`=[0.0025, 0.01, 0.1, 0.5, 0.8], `norm`=Linf\n",
        "2.   `num_selected_models`=[5, 10, 15, 20, 25, 30, 35, 40], `infer_noise`=0.1, `eps`=[0.0025, 0.01, 0.1, 0.5, 0.8], `norm`=Linf\n",
        "3.   `num_selected_models`=15, `infer_noise`=[0.0025, 0.005, 0.01, 0.05, 0.08, 0.1], `eps`=[0.1, 0.5, 0.8, 0.9, 1], `norm`=L2\n",
        "4.   `num_selected_models`=[5, 10, 15, 20, 25, 30, 35, 40], `infer_noise`=0.1, `eps`=[0.1, 0.5, 0.8, 0.9, 1], `norm`=L2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfpLU-YJlx92"
      },
      "source": [
        "### Arbitrary Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64xN40H5nqHR"
      },
      "source": [
        "num_selected_models = 50\n",
        "# norm = np.inf\n",
        "norm = 2\n",
        "infer_noise = 0.1\n",
        "# eps = 8/255\n",
        "eps = 0.5\n",
        "logging.info(\"Current experiment setting: eps={}, inference noise={}\".format(eps, infer_noise))\n",
        "my_ensemble_classifier = MyEnsembleClassifier(classifier_list,\n",
        "                                              device, \n",
        "                                              infer_noise=infer_noise,\n",
        "                                              num_selected_models=num_selected_models,\n",
        "                                              clip_values=[0., 1.], \n",
        "                                              channels_first=True)\n",
        "attack = ProjectedGradientDescentPyTorch(my_ensemble_classifier, eps=eps, eps_step=0.4, norm=norm, max_iter=20, batch_size=test_batchsize)\n",
        "Acc_adv = []\n",
        "Acc_nat = []\n",
        "for batch_idx, (X, Y) in enumerate(testloader):\n",
        "  x_test = X.numpy()\n",
        "  y_test = Y.numpy()\n",
        "  predictions_nat = my_ensemble_classifier.predict(x_test)\n",
        "  accuracy_nat = np.sum(np.argmax(predictions_nat, axis=1) == y_test) / len(y_test)\n",
        "  Acc_nat.append(accuracy_nat)\n",
        "\n",
        "  x_test_adv = attack.generate(torch.from_numpy(x_test), torch.from_numpy(y_test))\n",
        "  predictions_adv = my_ensemble_classifier.predict(x_test_adv)\n",
        "  accuracy_adv = np.sum(np.argmax(predictions_adv, axis=1) == y_test) / len(y_test)\n",
        "  Acc_adv.append(accuracy_adv)\n",
        "  \n",
        "  # print('accuracy (adversarial): {}'.format(accuracy_adv))\n",
        "  # print('accuracy (natural): {}'.format(accuracy_nat))\n",
        "\n",
        "  # logging.info('accuracy (adversarial): {}'.format(accuracy_adv))\n",
        "  # logging.info('accuracy (natural): {}'.format(accuracy_nat))\n",
        "    \n",
        "Acc_adv = np.asanyarray(Acc_adv)\n",
        "Acc_nat = np.asanyarray(Acc_nat)\n",
        "idx = np.arange(0, len(testset)/test_batchsize).tolist()\n",
        "res = {'Id': idx ,'AccADV': Acc_adv, 'AccNAT': Acc_nat} \n",
        "df = pd.DataFrame(res) \n",
        "# saving the dataframe \n",
        "df.to_csv('./gdrive/My Drive/IDL_Project/results/PGD_exp1_infer_noise{}_eps{}.csv'.format(infer_noise, eps),index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEzaTmhp7qFg"
      },
      "source": [
        "# Experiment 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIZS0qT17u3_"
      },
      "source": [
        "num_selected_models = 15\n",
        "norm = np.inf\n",
        "infer_noise_list = [0.0025, 0.005, 0.01, 0.05, 0.08, 0.1]\n",
        "eps_list = [0.0025, 0.01, 0.1, 0.5, 0.8]\n",
        "\n",
        "for infer_noise in infer_noise_list:\n",
        "  for eps in eps_list:\n",
        "    my_ensemble_classifier = MyEnsembleClassifier(classifier_list,\n",
        "                                                  device, \n",
        "                                                  infer_noise=infer_noise,\n",
        "                                                  num_selected_models=num_selected_models,\n",
        "                                                  clip_values=[0., 1.], \n",
        "                                                  channels_first=True)\n",
        "    attack = ProjectedGradientDescentPyTorch(my_ensemble_classifier, eps=eps, eps_step=eps/3, norm=norm)\n",
        "    Acc_adv = []\n",
        "    Acc_nat = []\n",
        "    for batch_idx, (X, Y) in enumerate(testloader):\n",
        "      x_test = X.numpy()\n",
        "      y_test = Y.numpy()\n",
        "      predictions_nat = my_ensemble_classifier.predict(x_test)\n",
        "      accuracy_nat = np.sum(np.argmax(predictions_nat, axis=1) == y_test) / len(y_test)\n",
        "      Acc_nat.append(accuracy_nat)\n",
        "\n",
        "      x_test_adv = attack.generate(torch.from_numpy(x_test), torch.from_numpy(y_test))\n",
        "      predictions_adv = my_ensemble_classifier.predict(x_test_adv)\n",
        "      accuracy_adv = np.sum(np.argmax(predictions_adv, axis=1) == y_test) / len(y_test)\n",
        "      Acc_adv.append(accuracy_adv)\n",
        "      \n",
        "      logging.info('accuracy (adversarial): {}'.format(accuracy_adv))\n",
        "      logging.info('accuracy (natural): {}'.format(accuracy_nat))\n",
        "    \n",
        "    Acc_adv = np.asanyarray(Acc_adv)\n",
        "    Acc_nat = np.asanyarray(Acc_nat)\n",
        "    idx = np.arange(0, len(testset)/test_batchsize).tolist()\n",
        "    res = {'Id': idx ,'AccADV': Acc_adv, 'AccNAT': Acc_nat} \n",
        "    df = pd.DataFrame(res) \n",
        "    # saving the dataframe \n",
        "    df.to_csv('./gdrive/My Drive/IDL_Project/results/PGD_exp1_infer_noise{}_eps{}.csv'.format(infer_noise, eps),index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH-xmYJL8n14"
      },
      "source": [
        "# Experiment 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e44AHWvw8qxI"
      },
      "source": [
        "num_selected_models_list = [5, 10, 15, 20, 25, 30, 35, 40]\n",
        "norm = np.inf\n",
        "infer_noise = 0.1\n",
        "eps_list = [0.0025, 0.01, 0.1, 0.5, 0.8]\n",
        "\n",
        "for num_selected_models in num_selected_models_list:\n",
        "  for eps in eps_list:\n",
        "    my_ensemble_classifier = MyEnsembleClassifier(classifier_list,\n",
        "                                                  device, \n",
        "                                                  infer_noise=infer_noise,\n",
        "                                                  num_selected_models=num_selected_models,\n",
        "                                                  clip_values=[0., 1.], \n",
        "                                                  channels_first=True)\n",
        "    attack = ProjectedGradientDescentPyTorch(my_ensemble_classifier, eps=eps, eps_step=eps/3, norm=norm)\n",
        "    Acc_adv = []\n",
        "    Acc_nat = []\n",
        "    for batch_idx, (X, Y) in enumerate(testloader):\n",
        "      x_test = X.numpy()\n",
        "      y_test = Y.numpy()\n",
        "      x_test_adv = attack.generate(torch.from_numpy(x_test), torch.from_numpy(y_test))\n",
        "      predictions_adv = my_ensemble_classifier.predict(x_test_adv)\n",
        "      predictions_nat = my_ensemble_classifier.predict(x_test)\n",
        "      accuracy_adv = np.sum(np.argmax(predictions_adv, axis=1) == y_test) / len(y_test)\n",
        "      accuracy_nat = np.sum(np.argmax(predictions_nat, axis=1) == y_test) / len(y_test)\n",
        "      Acc_adv.append(accuracy_adv)\n",
        "      Acc_nat.append(accuracy_nat)\n",
        "      logging.info('accuracy (adversarial): {}'.format(accuracy_adv))\n",
        "      logging.info('accuracy (natural): {}'.format(accuracy_nat))\n",
        "    \n",
        "    Acc_adv = np.asanyarray(Acc_adv)\n",
        "    Acc_nat = np.asanyarray(Acc_nat)\n",
        "    idx = np.arange(0, len(testset)/test_batchsize).tolist()\n",
        "    res = {'Id': idx ,'AccADV': Acc_adv, 'AccNAT': Acc_nat} \n",
        "    df = pd.DataFrame(res) \n",
        "    # saving the dataframe \n",
        "    df.to_csv('./gdrive/My Drive/IDL_Project/results/PGD_exp2_N{}_eps{}.csv'.format(num_selected_models, eps),index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ng7Xe9Zq8rai"
      },
      "source": [
        "# Experiment 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3rzYvCu8uoa"
      },
      "source": [
        "num_selected_models = 15\n",
        "norm = 2\n",
        "infer_noise_list = [0.0025, 0.005, 0.01, 0.05, 0.08, 0.1]\n",
        "eps_list = [0.1, 0.5, 0.8, 0.9, 1]\n",
        "\n",
        "for infer_noise in infer_noise_list:\n",
        "  for eps in eps_list:\n",
        "    my_ensemble_classifier = MyEnsembleClassifier(classifier_list,\n",
        "                                                  device, \n",
        "                                                  infer_noise=infer_noise,\n",
        "                                                  num_selected_models=num_selected_models,\n",
        "                                                  clip_values=[0., 1.], \n",
        "                                                  channels_first=True)\n",
        "    attack = ProjectedGradientDescentPyTorch(my_ensemble_classifier, eps=eps, eps_step=eps/3, norm=norm)\n",
        "    Acc_adv = []\n",
        "    Acc_nat = []\n",
        "    for batch_idx, (X, Y) in enumerate(testloader):\n",
        "      x_test = X.numpy()\n",
        "      y_test = Y.numpy()\n",
        "      x_test_adv = attack.generate(torch.from_numpy(x_test), torch.from_numpy(y_test))\n",
        "      predictions_adv = my_ensemble_classifier.predict(x_test_adv)\n",
        "      predictions_nat = my_ensemble_classifier.predict(x_test)\n",
        "      accuracy_adv = np.sum(np.argmax(predictions_adv, axis=1) == y_test) / len(y_test)\n",
        "      accuracy_nat = np.sum(np.argmax(predictions_nat, axis=1) == y_test) / len(y_test)\n",
        "      Acc_adv.append(accuracy_adv)\n",
        "      Acc_nat.append(accuracy_nat)\n",
        "      logging.info('accuracy (adversarial): {}'.format(accuracy_adv))\n",
        "      logging.info('accuracy (natural): {}'.format(accuracy_nat))\n",
        "    \n",
        "    Acc_adv = np.asanyarray(Acc_adv)\n",
        "    Acc_nat = np.asanyarray(Acc_nat)\n",
        "    idx = np.arange(0, len(testset)/test_batchsize).tolist()\n",
        "    res = {'Id': idx ,'AccADV': Acc_adv, 'AccNAT': Acc_nat} \n",
        "    df = pd.DataFrame(res) \n",
        "    # saving the dataframe \n",
        "    df.to_csv('./gdrive/My Drive/IDL_Project/results/PGD_exp3_infer_noise{}_eps{}.csv'.format(infer_noise, eps),index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-w5HNiC8vDY"
      },
      "source": [
        "# Experiment 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTCAdeqj8w17"
      },
      "source": [
        "num_selected_models_list = [5, 10, 15, 20, 25, 30, 35, 40]\n",
        "norm = 2\n",
        "infer_noise = 0.1\n",
        "eps_list = [0.1, 0.5, 0.8, 0.9, 1]\n",
        "\n",
        "for num_selected_models in num_selected_models_list:\n",
        "  for eps in eps_list:\n",
        "    my_ensemble_classifier = MyEnsembleClassifier(classifier_list,\n",
        "                                                  device, \n",
        "                                                  infer_noise=infer_noise,\n",
        "                                                  num_selected_models=num_selected_models,\n",
        "                                                  clip_values=[0., 1.], \n",
        "                                                  channels_first=True)\n",
        "    attack = ProjectedGradientDescentPyTorch(my_ensemble_classifier, eps=eps, eps_step=eps/3, norm=norm)\n",
        "    Acc_adv = []\n",
        "    Acc_nat = []\n",
        "    for batch_idx, (X, Y) in enumerate(testloader):\n",
        "      x_test = X.numpy()\n",
        "      y_test = Y.numpy()\n",
        "      x_test_adv = attack.generate(torch.from_numpy(x_test), torch.from_numpy(y_test))\n",
        "      predictions_adv = my_ensemble_classifier.predict(x_test_adv)\n",
        "      predictions_nat = my_ensemble_classifier.predict(x_test)\n",
        "      accuracy_adv = np.sum(np.argmax(predictions_adv, axis=1) == y_test) / len(y_test)\n",
        "      accuracy_nat = np.sum(np.argmax(predictions_nat, axis=1) == y_test) / len(y_test)\n",
        "      Acc_adv.append(accuracy_adv)\n",
        "      Acc_nat.append(accuracy_nat)\n",
        "      logging.info('accuracy (adversarial): {}'.format(accuracy_adv))\n",
        "      logging.info('accuracy (natural): {}'.format(accuracy_nat))\n",
        "    \n",
        "    Acc_adv = np.asanyarray(Acc_adv)\n",
        "    Acc_nat = np.asanyarray(Acc_nat)\n",
        "    idx = np.arange(0, len(testset)/test_batchsize).tolist()\n",
        "    res = {'Id': idx ,'AccADV': Acc_adv, 'AccNAT': Acc_nat} \n",
        "    df = pd.DataFrame(res) \n",
        "    # saving the dataframe \n",
        "    df.to_csv('./gdrive/My Drive/IDL_Project/results/PGD_exp4_N{}_eps{}.csv'.format(num_selected_models, eps),index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gP_Gxq-2jc-9"
      },
      "source": [
        "# FGM Attack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmXkglUUKXO3"
      },
      "source": [
        "attack = FastGradientMethod(estimator=my_ensemble_classifier, eps=0.5, targeted=False, norm=2)\n",
        "Acc = []\n",
        "for batch_idx, (X, Y) in enumerate(testloader):\n",
        "    x_test = X.numpy()\n",
        "    y_test = Y.numpy()\n",
        "    # target = (y_test + 1) % 10\n",
        "    x_test_adv = attack.generate(torch.from_numpy(x_test), torch.from_numpy(y_test))\n",
        "    predictions = my_ensemble_classifier.predict(x_test_adv)\n",
        "    predictions_test = my_ensemble_classifier.predict(x_test)\n",
        "    accuracy = np.sum(np.argmax(predictions, axis=1) == y_test) / len(y_test)\n",
        "    acc_test = np.sum(np.argmax(predictions_test, axis=1) == y_test) / len(y_test)\n",
        "    # print(y_test.shape)\n",
        "    # acc_rate, coverage_rate = compute_accuracy(preds=predictions, labels=np.reshape(y_test, (test_batchsize, 1)))\n",
        "    # logging.info('acc rate: {}, coverage rate: {}'.format(acc_rate, coverage_rate))\n",
        "    Acc.append(accuracy)\n",
        "    logging.info('accuracy: {}'.format(accuracy))\n",
        "    logging.info('accuracy non adv: {}'.format(acc_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoYiKeGCjfDR"
      },
      "source": [
        "# PGD Attack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZRM5XEZjchO"
      },
      "source": [
        "attack = ProjectedGradientDescentPyTorch(my_ensemble_classifier, eps=0.5, eps_step=0.03)\n",
        "Acc = []\n",
        "for batch_idx, (X, Y) in enumerate(testloader):\n",
        "    x_test = X.numpy()\n",
        "    y_test = Y.numpy()\n",
        "    x_test_adv = attack.generate(torch.from_numpy(x_test))\n",
        "    predictions = my_ensemble_classifier.predict(x_test_adv)\n",
        "    accuracy = np.sum(np.argmax(predictions, axis=1) == np.array(y_test)) / len(y_test)\n",
        "    Acc.append(accuracy)\n",
        "    logging.info('accuracy: {}'.format(accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyMeGON8BFNL"
      },
      "source": [
        "# Experiment settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjUPKB3jvijF"
      },
      "source": [
        "fgm_epsilon = np.array([0.005, 0.01, 0.02, 0.04, 0.08])\n",
        "pgd_epsilon = 8.0 / 255.0 / np.array([2.0, 4.0, 8.0, 16.0])\n",
        "diff = np.array([1e-3, 1e-4, 1e-5, 1e-6])\n",
        "pgd_epsilon_step = pgd_epsilon - diff"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XG44M27BNIT"
      },
      "source": [
        "Experiment on inference noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U79zJmCsDEKc"
      },
      "source": [
        "noise_stds = [0.02, 0.04, 0.06, 0.08, 0.1]\n",
        "for i in range(len(noise_stds)):\n",
        "  my_ensemble = MyEnsemble(model_dict, num_models_selected, noise_std=noise_stds[i], num_classes=10)\n",
        "  classifier = PyTorchClassifier(\n",
        "      model=my_ensemble,\n",
        "      clip_values=(0, 1),\n",
        "      loss=nn.CrossEntropyLoss(),\n",
        "      input_shape=(3, 224, 224),\n",
        "      nb_classes=10)\n",
        "  attack = FastGradientMethod(estimator=classifier, eps=0.01)\n",
        "  Acc = []\n",
        "  for batch_idx, (X, Y) in enumerate(testloader):\n",
        "    x_test = X.numpy()\n",
        "    y_test = Y.numpy()\n",
        "    x_test_adv = attack.generate(torch.from_numpy(x_test))\n",
        "    predictions = classifier.predict(x_test_adv)\n",
        "    accuracy = np.sum(np.argmax(predictions, axis=1) == np.array(y_test)) / len(y_test)\n",
        "    Acc.append(accuracy)\n",
        "    logging.info('accuracy: {}'.format(accuracy))\n",
        "  \n",
        "  logging.info(\"Accuracy for eps={}: {}\".format(fgm_epsilon[i], np.mean(np.array(Acc))))\n",
        "\n",
        "  pred_list = np.asanyarray(Acc)\n",
        "  idx = np.arange(0,len(testset)/test_batchsize).tolist()\n",
        "  dict = {'Id': idx ,'acc': pred_list} \n",
        "  df = pd.DataFrame(dict) \n",
        "  # saving the dataframe \n",
        "  df.to_csv('./gdrive/My Drive/IDL_Project/results/FGM_result_noise{}_{}.csv'.format(noise_stds[i], datetime.datetime.now()),index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LotwWsVpMYKN"
      },
      "source": [
        "pred_list = np.asanyarray(Acc)\n",
        "idx = np.arange(0,len(testset)/test_batchsize).tolist()\n",
        "dict = {'Id': idx ,'acc': pred_list} \n",
        "df = pd.DataFrame(dict) \n",
        "# saving the dataframe \n",
        "df.to_csv('./gdrive/My Drive/IDL_Project/results/FGM_result_eps{}_{}.csv'.format(fgm_epsilon[-1], datetime.datetime.now()),index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqIgjfhwBXVL"
      },
      "source": [
        "# Plot Adversarial Examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Eu7qdDQMnGq"
      },
      "source": [
        "# create ensemble classifier\n",
        "my_ensemble_classifier = MyEnsembleClassifier(classifier_list,\n",
        "                                              device, \n",
        "                                              infer_noise=infer_noise,\n",
        "                                              num_selected_models=num_selected_models,\n",
        "                                              clip_values=[0., 1.], \n",
        "                                              channels_first=True)\n",
        "\n",
        "# create attack object\n",
        "attack = ProjectedGradientDescentPyTorch(my_ensemble_classifier, \n",
        "                                         eps=eps, \n",
        "                                         eps_step=eps_step, \n",
        "                                         norm=norm, \n",
        "                                         max_iter=max_iter, \n",
        "                                         batch_size=test_batchsize)\n",
        "\n",
        "# kick off experiment\n",
        "Acc_adv = []\n",
        "Acc_nat = []\n",
        "adv = []\n",
        "orig = []\n",
        "labels = []\n",
        "pred = []\n",
        "for batch_idx, (X, Y) in enumerate(testloader):\n",
        "  x_test = X.numpy()\n",
        "  y_test = Y.numpy()\n",
        "  predictions_nat = my_ensemble_classifier.predict(x_test)\n",
        "  accuracy_nat = np.sum(np.argmax(predictions_nat, axis=1) == y_test) / len(y_test)\n",
        "  Acc_nat.append(accuracy_nat)\n",
        "\n",
        "  x_test_adv = attack.generate(torch.from_numpy(x_test), torch.from_numpy(y_test))\n",
        "  predictions_adv = my_ensemble_classifier.predict(x_test_adv)\n",
        "  accuracy_adv = np.sum(np.argmax(predictions_adv, axis=1) == y_test) / len(y_test)\n",
        "  Acc_adv.append(accuracy_adv)\n",
        "\n",
        "  adv.append(x_test_adv)\n",
        "  orig.append(x_test)\n",
        "  labels.append(y_test)\n",
        "  pred.append(predictions_adv)\n",
        "\n",
        "  logging.info('accuracy (adversarial): {}'.format(accuracy_adv))\n",
        "  logging.info('accuracy (natural): {}'.format(accuracy_nat))\n",
        "  break\n",
        "    \n",
        "\n",
        "# # saving the dataframe \n",
        "# Acc_adv = np.asanyarray(Acc_adv)\n",
        "# Acc_nat = np.asanyarray(Acc_nat)\n",
        "# res = {'AccADV': Acc_adv, 'AccNAT': Acc_nat} \n",
        "# df = pd.DataFrame(res)\n",
        "# df.to_csv('./gdrive/My Drive/IDL_Project/results/result_{}models_{}samples.csv'.format(len(model_names), num_selected_models),index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8sj2LdnNV5n"
      },
      "source": [
        "example_adv = adv[-1]\n",
        "example_orig = orig[-1]\n",
        "label = labels[-1]\n",
        "predi = np.argmax(predictions, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoD6QHEwNt4T"
      },
      "source": [
        "print(label)\n",
        "print(predi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnkXnHRePFeW"
      },
      "source": [
        "idx = 2\n",
        "selected_adv = example_adv[idx]\n",
        "selected_orig = example_orig[idx]\n",
        "selected_lab = label[idx]\n",
        "selected_pred = predi[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZuD1OfoWroX"
      },
      "source": [
        "print(selected_lab)\n",
        "print(selected_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkxSl4PTPab0"
      },
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(np.transpose(selected_orig, (1, 2, 0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tpehq_0hVobG"
      },
      "source": [
        "plt.imshow(np.transpose(selected_adv, (1, 2, 0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuLSJh8QVsHy"
      },
      "source": [
        "plt.imshow(10*(np.transpose(selected_orig, (1, 2, 0)) - np.transpose(selected_adv, (1, 2, 0))))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}