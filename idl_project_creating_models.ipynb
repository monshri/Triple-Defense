{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "idl_project_creating_models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Environment (conda_pytorch_latest_p37)",
      "language": "python",
      "name": "conda_pytorch_latest_p37"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaichengDING/Triple-Defense/blob/main/idl_project_creating_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcnIH59Pvv4n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f1cd1d2-c1c2-4313-ae0b-9a2eff6446ed"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SqUPdAKkDIn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "466fe5f1-1529-45af-831e-3d23a1853085"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import PIL\n",
        "\n",
        "import sys\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "\n",
        "from torch.utils import data\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import logging\n",
        "import datetime\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "cuda"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfyaOczXoRqQ"
      },
      "source": [
        "class AddGaussianNoise(object):\n",
        "    def __init__(self, mean=0.0, std=1.0, dropout=0.5):\n",
        "        self.std = std\n",
        "        self.mean = mean\n",
        "        self.dropout = dropout\n",
        "        \n",
        "    def __call__(self, tensor):\n",
        "      mask = torch.rand(tensor.size()) >= self.dropout\n",
        "      noise = torch.randn(tensor.size()) * self.std + self.mean\n",
        "      noise = noise * mask\n",
        "      res = tensor + noise\n",
        "      return torch.clamp(input=res, min=0.0, max=1.0)\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkIqO0-ntgcy"
      },
      "source": [
        "def train_epoch(model, train_loader, criterion, optimizer):\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    total_predictions = 0.0\n",
        "    correct_predictions = 0.0\n",
        "    \n",
        "    for batch_idx, (data, target) in enumerate(train_loader):   \n",
        "        optimizer.zero_grad()   # .backward() accumulates gradients\n",
        "        data = data.to(device)\n",
        "        target = target.to(device) # all data & model on same device\n",
        "        \n",
        "        with torch.cuda.amp.autocast():\n",
        "          outputs = model(data)\n",
        "          loss = criterion(outputs, target)\n",
        "          running_loss += loss.item()\n",
        "\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total_predictions += target.size(0)\n",
        "          correct_predictions += (predicted == target).sum().item()\n",
        "        \n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "\n",
        "        del data\n",
        "        del target\n",
        "    \n",
        "    \n",
        "    running_loss /= len(train_loader)\n",
        "    acc = (correct_predictions/total_predictions)*100.0\n",
        "    logging.info('Training Loss: {}'.format(running_loss))\n",
        "    logging.info('Training Accuracy: {}%'.format(acc))\n",
        "    return running_loss\n",
        "\n",
        "\n",
        "def test_model(model, test_loader, criterion):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "\n",
        "        running_loss = 0.0\n",
        "        total_predictions = 0.0\n",
        "        correct_predictions = 0.0\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(test_loader): \n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "              outputs = model(data)\n",
        "\n",
        "              _, predicted = torch.max(outputs.data, 1)\n",
        "              total_predictions += target.size(0)\n",
        "              correct_predictions += (predicted == target).sum().item()\n",
        "\n",
        "              loss = criterion(outputs, target).detach()\n",
        "              running_loss += loss.item()\n",
        "\n",
        "            del data\n",
        "            del target\n",
        "\n",
        "        running_loss /= len(test_loader)\n",
        "        acc = (correct_predictions/total_predictions)*100.0\n",
        "        logging.info('Testing Loss: {}'.format(running_loss))\n",
        "        logging.info('Testing Accuracy: {}%'.format(acc))\n",
        "        return running_loss, acc\n",
        "\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Conv2d or type(m) == nn.Linear:\n",
        "        torch.nn.init.xavier_normal_(m.weight.data)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXX4443Y16Ul"
      },
      "source": [
        "# configure logging\n",
        "logger = logging.getLogger(\"\")\n",
        "\n",
        "# reset handler\n",
        "for handler in logging.root.handlers[:]:\n",
        "  logging.root.removeHandler(handler)\n",
        "\n",
        "# set handler\n",
        "stream_hdlr = logging.StreamHandler()\n",
        "file_hdlr = logging.FileHandler('/content/gdrive/My Drive/IDL_Project/logs/log_{}.log.log'.format(datetime.datetime.now()))\n",
        "\n",
        "formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
        "stream_hdlr.setFormatter(formatter)\n",
        "file_hdlr.setFormatter(formatter)\n",
        "\n",
        "logger.addHandler(stream_hdlr)\n",
        "logger.addHandler(file_hdlr)\n",
        "\n",
        "logger.setLevel(logging.INFO)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq_mk_bEBtlt"
      },
      "source": [
        "class ShuffleNet(nn.Module):\n",
        "    def __init__(self, nb_classes =10):\n",
        "        super(ShuffleNet, self).__init__()\n",
        "        self.shuffle = models.shufflenet_v2_x2_0()\n",
        "        self.linear = nn.Linear(1000, nb_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.shuffle(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFZ8ZtrqxZ7j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "351a7e2c-55f9-4a23-e21b-114294a99a3a"
      },
      "source": [
        "train_batchsize = 128\n",
        "test_batchsize = 100\n",
        "num_workers = 8\n",
        "num_classes = 10\n",
        "\n",
        "n_epochs = 60\n",
        "img_size = 224\n",
        "lr = 1e-4\n",
        "min_lr = 1e-8\n",
        "weight_decay = 5e-4\n",
        "num_models = 30\n",
        "\n",
        "noise_std = 0.1\n",
        "noise_dropout = 0.0\n",
        "\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "\n",
        "hyper_params = {'lr': lr, \n",
        "                'min_lr': min_lr, \n",
        "                'weight_decay': weight_decay, \n",
        "                'num_models': num_models, \n",
        "                'num_epochs': n_epochs, \n",
        "                'noise_std': noise_std, \n",
        "                'noise_dropout':noise_dropout}\n",
        "logging.info(hyper_params)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-06 05:31:38,774 INFO {'lr': 0.0001, 'min_lr': 1e-08, 'weight_decay': 0.0005, 'num_models': 30, 'num_epochs': 60, 'noise_std': 0.1, 'noise_dropout': 0.0}\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUfvg4LvwMA0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "150e186e-f68b-40ab-b7b8-a49e520b5603"
      },
      "source": [
        "seeds = np.arange(0, num_models)\n",
        "\n",
        "for seed in seeds:\n",
        "  logging.info('Seed: {}'.format(seed))\n",
        "  torch.manual_seed(seed)\n",
        "  \n",
        "\n",
        "  train_transform = transforms.Compose([transforms.Resize(size=img_size),\n",
        "                      transforms.ColorJitter(hue=.05, saturation=.05),\n",
        "                      transforms.RandomHorizontalFlip(p=0.5),\n",
        "                      transforms.RandomRotation(20, resample=PIL.Image.BILINEAR),\n",
        "                      transforms.ToTensor(),\n",
        "                      transforms.Normalize((0, 0, 0), (1, 1, 1)),\n",
        "                      AddGaussianNoise(0., noise_std, noise_dropout)])\n",
        "\n",
        "  test_transform = transforms.Compose([transforms.Resize(size=img_size),\n",
        "                     transforms.ToTensor(),\n",
        "                     transforms.Normalize((0, 0, 0), (1, 1, 1)),\n",
        "                     AddGaussianNoise(0., noise_std, noise_dropout)])\n",
        "\n",
        "  \n",
        "  trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
        "  testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
        "  trainloader = torch.utils.data.DataLoader(trainset, batch_size=train_batchsize, shuffle=True, num_workers=num_workers)\n",
        "  testloader = torch.utils.data.DataLoader(testset, batch_size=test_batchsize, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "  model = ShuffleNet(num_classes)\n",
        "  model.apply(init_weights)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "  scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=1, cooldown=5, min_lr=min_lr, verbose=True)\n",
        "  scaler = torch.cuda.amp.GradScaler()\n",
        "  model.to(device)\n",
        "\n",
        "  # Train_loss = []\n",
        "  # Test_loss = []\n",
        "  # Test_acc = []\n",
        "\n",
        "  for i in range(n_epochs):\n",
        "    tic = time.time()\n",
        "    logging.info('Epoch: {}'.format(i))\n",
        "    train_loss = train_epoch(model, trainloader, criterion, optimizer)\n",
        "    test_loss, test_acc = test_model(model, testloader, criterion)\n",
        "    scheduler.step(test_loss)\n",
        "    # Train_loss.append(train_loss)\n",
        "    # Test_loss.append(test_loss)\n",
        "    # Test_acc.append(test_acc)\n",
        "    toc = time.time()\n",
        "    logging.info('Time: {}s'.format(toc - tic))\n",
        "    logging.info('='*20)\n",
        "    \n",
        "  torch.save({'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'scheduler_state_dict': scheduler.state_dict()}, \n",
        "        \"/content/gdrive/My Drive/IDL_Project/modelS/Model_shufflenet{}_std{}_dropout{}\".format(seed, noise_std, noise_dropout))\n",
        "  \n",
        "  torch.cuda.empty_cache()\n",
        "  del model\n",
        "  del criterion\n",
        "  del optimizer\n",
        "  del scheduler\n",
        "  del scaler\n",
        "  del trainloader\n",
        "  del testloader\n",
        "  del train_transform\n",
        "  del test_transform\n",
        "\n",
        "  \n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-06 05:31:41,067 INFO Seed: 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-12-06 05:31:42,961 INFO Epoch: 0\n",
            "2020-12-06 05:36:03,765 INFO Training Loss: 1.9401713414570254\n",
            "2020-12-06 05:36:03,767 INFO Training Accuracy: 28.198%\n",
            "2020-12-06 05:36:28,050 INFO Testing Loss: 1.7628186535835266\n",
            "2020-12-06 05:36:28,052 INFO Testing Accuracy: 35.75%\n",
            "2020-12-06 05:36:28,053 INFO Time: 285.09193444252014s\n",
            "2020-12-06 05:36:28,054 INFO ====================\n",
            "2020-12-06 05:36:28,056 INFO Epoch: 1\n",
            "2020-12-06 05:40:50,859 INFO Training Loss: 1.6809083250782373\n",
            "2020-12-06 05:40:50,862 INFO Training Accuracy: 37.976%\n",
            "2020-12-06 05:41:15,523 INFO Testing Loss: 1.5854601502418517\n",
            "2020-12-06 05:41:15,525 INFO Testing Accuracy: 42.199999999999996%\n",
            "2020-12-06 05:41:15,526 INFO Time: 287.4700357913971s\n",
            "2020-12-06 05:41:15,527 INFO ====================\n",
            "2020-12-06 05:41:15,529 INFO Epoch: 2\n",
            "2020-12-06 05:45:39,776 INFO Training Loss: 1.5419034360314878\n",
            "2020-12-06 05:45:39,778 INFO Training Accuracy: 43.146%\n",
            "2020-12-06 05:46:04,502 INFO Testing Loss: 1.4594215989112853\n",
            "2020-12-06 05:46:04,504 INFO Testing Accuracy: 46.06%\n",
            "2020-12-06 05:46:04,505 INFO Time: 288.9762451648712s\n",
            "2020-12-06 05:46:04,506 INFO ====================\n",
            "2020-12-06 05:46:04,508 INFO Epoch: 3\n",
            "2020-12-06 05:50:29,018 INFO Training Loss: 1.4557187962714973\n",
            "2020-12-06 05:50:29,020 INFO Training Accuracy: 46.98%\n",
            "2020-12-06 05:50:53,604 INFO Testing Loss: 1.3681092965602875\n",
            "2020-12-06 05:50:53,606 INFO Testing Accuracy: 50.55%\n",
            "2020-12-06 05:50:53,607 INFO Time: 289.09898829460144s\n",
            "2020-12-06 05:50:53,609 INFO ====================\n",
            "2020-12-06 05:50:53,610 INFO Epoch: 4\n",
            "2020-12-06 05:55:19,198 INFO Training Loss: 1.3691666065274601\n",
            "2020-12-06 05:55:19,200 INFO Training Accuracy: 50.392%\n",
            "2020-12-06 05:55:43,961 INFO Testing Loss: 1.2818568515777589\n",
            "2020-12-06 05:55:43,963 INFO Testing Accuracy: 54.1%\n",
            "2020-12-06 05:55:43,964 INFO Time: 290.35361313819885s\n",
            "2020-12-06 05:55:43,965 INFO ====================\n",
            "2020-12-06 05:55:43,966 INFO Epoch: 5\n",
            "2020-12-06 06:00:10,428 INFO Training Loss: 1.2912647660126162\n",
            "2020-12-06 06:00:10,430 INFO Training Accuracy: 53.576%\n",
            "2020-12-06 06:00:35,107 INFO Testing Loss: 1.2526980245113373\n",
            "2020-12-06 06:00:35,108 INFO Testing Accuracy: 54.58%\n",
            "2020-12-06 06:00:35,110 INFO Time: 291.1438834667206s\n",
            "2020-12-06 06:00:35,112 INFO ====================\n",
            "2020-12-06 06:00:35,113 INFO Epoch: 6\n",
            "2020-12-06 06:05:01,039 INFO Training Loss: 1.2214610194001356\n",
            "2020-12-06 06:05:01,041 INFO Training Accuracy: 56.248%\n",
            "2020-12-06 06:05:25,814 INFO Testing Loss: 1.1548590487241746\n",
            "2020-12-06 06:05:25,815 INFO Testing Accuracy: 58.60999999999999%\n",
            "2020-12-06 06:05:25,816 INFO Time: 290.7031729221344s\n",
            "2020-12-06 06:05:25,818 INFO ====================\n",
            "2020-12-06 06:05:25,819 INFO Epoch: 7\n",
            "2020-12-06 06:09:51,348 INFO Training Loss: 1.1473557807295525\n",
            "2020-12-06 06:09:51,351 INFO Training Accuracy: 59.156%\n",
            "2020-12-06 06:10:16,010 INFO Testing Loss: 1.115545580983162\n",
            "2020-12-06 06:10:16,012 INFO Testing Accuracy: 60.68%\n",
            "2020-12-06 06:10:16,013 INFO Time: 290.19425916671753s\n",
            "2020-12-06 06:10:16,014 INFO ====================\n",
            "2020-12-06 06:10:16,015 INFO Epoch: 8\n",
            "2020-12-06 06:14:42,021 INFO Training Loss: 1.0747689525489612\n",
            "2020-12-06 06:14:42,023 INFO Training Accuracy: 61.79%\n",
            "2020-12-06 06:15:06,731 INFO Testing Loss: 1.0360878056287766\n",
            "2020-12-06 06:15:06,733 INFO Testing Accuracy: 62.64999999999999%\n",
            "2020-12-06 06:15:06,734 INFO Time: 290.7190363407135s\n",
            "2020-12-06 06:15:06,735 INFO ====================\n",
            "2020-12-06 06:15:06,736 INFO Epoch: 9\n",
            "2020-12-06 06:19:32,621 INFO Training Loss: 1.015865965420023\n",
            "2020-12-06 06:19:32,623 INFO Training Accuracy: 63.77%\n",
            "2020-12-06 06:19:57,408 INFO Testing Loss: 0.9757308536767959\n",
            "2020-12-06 06:19:57,409 INFO Testing Accuracy: 65.45%\n",
            "2020-12-06 06:19:57,411 INFO Time: 290.6746566295624s\n",
            "2020-12-06 06:19:57,412 INFO ====================\n",
            "2020-12-06 06:19:57,413 INFO Epoch: 10\n",
            "2020-12-06 06:24:21,969 INFO Training Loss: 0.9523778310822099\n",
            "2020-12-06 06:24:21,971 INFO Training Accuracy: 66.27199999999999%\n",
            "2020-12-06 06:24:46,675 INFO Testing Loss: 0.9032051426172256\n",
            "2020-12-06 06:24:46,676 INFO Testing Accuracy: 67.75999999999999%\n",
            "2020-12-06 06:24:46,678 INFO Time: 289.26403403282166s\n",
            "2020-12-06 06:24:46,679 INFO ====================\n",
            "2020-12-06 06:24:46,681 INFO Epoch: 11\n",
            "2020-12-06 06:29:12,272 INFO Training Loss: 0.8937342008361426\n",
            "2020-12-06 06:29:12,273 INFO Training Accuracy: 68.184%\n",
            "2020-12-06 06:29:37,167 INFO Testing Loss: 0.9183993619680405\n",
            "2020-12-06 06:29:37,168 INFO Testing Accuracy: 67.95%\n",
            "2020-12-06 06:29:37,170 INFO Time: 290.4890921115875s\n",
            "2020-12-06 06:29:37,171 INFO ====================\n",
            "2020-12-06 06:29:37,172 INFO Epoch: 12\n",
            "2020-12-06 06:34:03,751 INFO Training Loss: 0.8384914722893854\n",
            "2020-12-06 06:34:03,753 INFO Training Accuracy: 70.638%\n",
            "2020-12-06 06:34:28,483 INFO Testing Loss: 0.8318247818946838\n",
            "2020-12-06 06:34:28,485 INFO Testing Accuracy: 71.31%\n",
            "2020-12-06 06:34:28,486 INFO Time: 291.3138370513916s\n",
            "2020-12-06 06:34:28,488 INFO ====================\n",
            "2020-12-06 06:34:28,489 INFO Epoch: 13\n",
            "2020-12-06 06:38:53,651 INFO Training Loss: 0.7863881746521386\n",
            "2020-12-06 06:38:53,653 INFO Training Accuracy: 72.222%\n",
            "2020-12-06 06:39:18,367 INFO Testing Loss: 0.8244487261772155\n",
            "2020-12-06 06:39:18,369 INFO Testing Accuracy: 71.07%\n",
            "2020-12-06 06:39:18,370 INFO Time: 289.88084292411804s\n",
            "2020-12-06 06:39:18,371 INFO ====================\n",
            "2020-12-06 06:39:18,372 INFO Epoch: 14\n",
            "2020-12-06 06:43:44,001 INFO Training Loss: 0.7381630944626411\n",
            "2020-12-06 06:43:44,003 INFO Training Accuracy: 73.86399999999999%\n",
            "2020-12-06 06:44:08,804 INFO Testing Loss: 0.7760207813978195\n",
            "2020-12-06 06:44:08,806 INFO Testing Accuracy: 73.42999999999999%\n",
            "2020-12-06 06:44:08,807 INFO Time: 290.43428683280945s\n",
            "2020-12-06 06:44:08,809 INFO ====================\n",
            "2020-12-06 06:44:08,810 INFO Epoch: 15\n",
            "2020-12-06 06:48:35,108 INFO Training Loss: 0.6925724531378588\n",
            "2020-12-06 06:48:35,110 INFO Training Accuracy: 75.664%\n",
            "2020-12-06 06:48:59,877 INFO Testing Loss: 0.7375961589813232\n",
            "2020-12-06 06:48:59,878 INFO Testing Accuracy: 74.75%\n",
            "2020-12-06 06:48:59,880 INFO Time: 291.069130897522s\n",
            "2020-12-06 06:48:59,881 INFO ====================\n",
            "2020-12-06 06:48:59,883 INFO Epoch: 16\n",
            "2020-12-06 06:53:25,883 INFO Training Loss: 0.6526425332212082\n",
            "2020-12-06 06:53:25,886 INFO Training Accuracy: 76.79%\n",
            "2020-12-06 06:53:50,558 INFO Testing Loss: 0.7471103835105896\n",
            "2020-12-06 06:53:50,560 INFO Testing Accuracy: 74.26%\n",
            "2020-12-06 06:53:50,561 INFO Time: 290.67804527282715s\n",
            "2020-12-06 06:53:50,562 INFO ====================\n",
            "2020-12-06 06:53:50,563 INFO Epoch: 17\n",
            "2020-12-06 06:58:16,554 INFO Training Loss: 0.6118572184344386\n",
            "2020-12-06 06:58:16,555 INFO Training Accuracy: 78.346%\n",
            "2020-12-06 06:58:41,220 INFO Testing Loss: 0.6844486758112908\n",
            "2020-12-06 06:58:41,222 INFO Testing Accuracy: 76.75%\n",
            "2020-12-06 06:58:41,224 INFO Time: 290.66038060188293s\n",
            "2020-12-06 06:58:41,225 INFO ====================\n",
            "2020-12-06 06:58:41,226 INFO Epoch: 18\n",
            "2020-12-06 07:03:07,168 INFO Training Loss: 0.5763577706826007\n",
            "2020-12-06 07:03:07,170 INFO Training Accuracy: 79.778%\n",
            "2020-12-06 07:03:31,870 INFO Testing Loss: 0.6932935759425163\n",
            "2020-12-06 07:03:31,871 INFO Testing Accuracy: 76.25%\n",
            "2020-12-06 07:03:31,873 INFO Time: 290.6463816165924s\n",
            "2020-12-06 07:03:31,874 INFO ====================\n",
            "2020-12-06 07:03:31,876 INFO Epoch: 19\n",
            "2020-12-06 07:07:57,986 INFO Training Loss: 0.5335922292278855\n",
            "2020-12-06 07:07:57,987 INFO Training Accuracy: 81.418%\n",
            "2020-12-06 07:08:22,901 INFO Testing Loss: 0.67944644510746\n",
            "2020-12-06 07:08:22,902 INFO Testing Accuracy: 77.09%\n",
            "2020-12-06 07:08:22,903 INFO Time: 291.02762246131897s\n",
            "2020-12-06 07:08:22,905 INFO ====================\n",
            "2020-12-06 07:08:22,906 INFO Epoch: 20\n",
            "2020-12-06 07:12:49,968 INFO Training Loss: 0.5040522041680563\n",
            "2020-12-06 07:12:49,969 INFO Training Accuracy: 82.206%\n",
            "2020-12-06 07:13:14,598 INFO Testing Loss: 0.7784929057955742\n",
            "2020-12-06 07:13:14,599 INFO Testing Accuracy: 74.67%\n",
            "2020-12-06 07:13:14,601 INFO Time: 291.69497203826904s\n",
            "2020-12-06 07:13:14,603 INFO ====================\n",
            "2020-12-06 07:13:14,604 INFO Epoch: 21\n",
            "2020-12-06 07:17:41,513 INFO Training Loss: 0.4742668072509644\n",
            "2020-12-06 07:17:41,515 INFO Training Accuracy: 83.408%\n",
            "2020-12-06 07:18:06,365 INFO Testing Loss: 0.6574399384856224\n",
            "2020-12-06 07:18:06,367 INFO Testing Accuracy: 78.33%\n",
            "2020-12-06 07:18:06,369 INFO Time: 291.7650125026703s\n",
            "2020-12-06 07:18:06,371 INFO ====================\n",
            "2020-12-06 07:18:06,372 INFO Epoch: 22\n",
            "2020-12-06 07:22:31,592 INFO Training Loss: 0.44096083645625495\n",
            "2020-12-06 07:22:31,593 INFO Training Accuracy: 84.666%\n",
            "2020-12-06 07:22:56,429 INFO Testing Loss: 0.6502302289009094\n",
            "2020-12-06 07:22:56,430 INFO Testing Accuracy: 78.64999999999999%\n",
            "2020-12-06 07:22:56,431 INFO Time: 290.0593559741974s\n",
            "2020-12-06 07:22:56,432 INFO ====================\n",
            "2020-12-06 07:22:56,433 INFO Epoch: 23\n",
            "2020-12-06 07:27:22,844 INFO Training Loss: 0.4218911863958744\n",
            "2020-12-06 07:27:22,845 INFO Training Accuracy: 85.038%\n",
            "2020-12-06 07:27:47,951 INFO Testing Loss: 0.6510887455940246\n",
            "2020-12-06 07:27:47,953 INFO Testing Accuracy: 79.14999999999999%\n",
            "2020-12-06 07:27:47,954 INFO Time: 291.5201647281647s\n",
            "2020-12-06 07:27:47,954 INFO ====================\n",
            "2020-12-06 07:27:47,955 INFO Epoch: 24\n",
            "2020-12-06 07:32:14,544 INFO Training Loss: 0.39323434447083633\n",
            "2020-12-06 07:32:14,546 INFO Training Accuracy: 86.00999999999999%\n",
            "2020-12-06 07:32:39,454 INFO Testing Loss: 0.661942834854126\n",
            "2020-12-06 07:32:39,456 INFO Testing Accuracy: 78.94%\n",
            "2020-12-06 07:32:39,459 INFO Time: 291.5037169456482s\n",
            "2020-12-06 07:32:39,460 INFO ====================\n",
            "2020-12-06 07:32:39,461 INFO Epoch: 25\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch    25: reducing learning rate of group 0 to 1.0000e-05.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-12-06 07:37:06,119 INFO Training Loss: 0.2995814990890605\n",
            "2020-12-06 07:37:06,121 INFO Training Accuracy: 89.778%\n",
            "2020-12-06 07:37:30,826 INFO Testing Loss: 0.5663109876215457\n",
            "2020-12-06 07:37:30,827 INFO Testing Accuracy: 81.38%\n",
            "2020-12-06 07:37:30,829 INFO Time: 291.3675925731659s\n",
            "2020-12-06 07:37:30,831 INFO ====================\n",
            "2020-12-06 07:37:30,832 INFO Epoch: 26\n",
            "2020-12-06 07:41:57,094 INFO Training Loss: 0.26584649194613136\n",
            "2020-12-06 07:41:57,096 INFO Training Accuracy: 90.996%\n",
            "2020-12-06 07:42:22,111 INFO Testing Loss: 0.5604530218243599\n",
            "2020-12-06 07:42:22,113 INFO Testing Accuracy: 81.42%\n",
            "2020-12-06 07:42:22,114 INFO Time: 291.2822616100311s\n",
            "2020-12-06 07:42:22,115 INFO ====================\n",
            "2020-12-06 07:42:22,117 INFO Epoch: 27\n",
            "2020-12-06 07:46:49,153 INFO Training Loss: 0.2529543177474795\n",
            "2020-12-06 07:46:49,155 INFO Training Accuracy: 91.418%\n",
            "2020-12-06 07:47:14,100 INFO Testing Loss: 0.569378237426281\n",
            "2020-12-06 07:47:14,102 INFO Testing Accuracy: 81.74%\n",
            "2020-12-06 07:47:14,103 INFO Time: 291.9866623878479s\n",
            "2020-12-06 07:47:14,105 INFO ====================\n",
            "2020-12-06 07:47:14,106 INFO Epoch: 28\n",
            "2020-12-06 07:51:40,566 INFO Training Loss: 0.2434455648903042\n",
            "2020-12-06 07:51:40,568 INFO Training Accuracy: 91.782%\n",
            "2020-12-06 07:52:05,394 INFO Testing Loss: 0.5637832157313823\n",
            "2020-12-06 07:52:05,396 INFO Testing Accuracy: 82.06%\n",
            "2020-12-06 07:52:05,396 INFO Time: 291.29077982902527s\n",
            "2020-12-06 07:52:05,398 INFO ====================\n",
            "2020-12-06 07:52:05,398 INFO Epoch: 29\n",
            "2020-12-06 07:56:32,539 INFO Training Loss: 0.2337958922280985\n",
            "2020-12-06 07:56:32,540 INFO Training Accuracy: 92.038%\n",
            "2020-12-06 07:56:57,264 INFO Testing Loss: 0.5791806498169899\n",
            "2020-12-06 07:56:57,266 INFO Testing Accuracy: 81.93%\n",
            "2020-12-06 07:56:57,267 INFO Time: 291.8685224056244s\n",
            "2020-12-06 07:56:57,268 INFO ====================\n",
            "2020-12-06 07:56:57,270 INFO Epoch: 30\n",
            "2020-12-06 08:01:24,433 INFO Training Loss: 0.224776359355968\n",
            "2020-12-06 08:01:24,434 INFO Training Accuracy: 92.44%\n",
            "2020-12-06 08:01:49,250 INFO Testing Loss: 0.5850475707650185\n",
            "2020-12-06 08:01:49,252 INFO Testing Accuracy: 81.8%\n",
            "2020-12-06 08:01:49,253 INFO Time: 291.9835591316223s\n",
            "2020-12-06 08:01:49,256 INFO ====================\n",
            "2020-12-06 08:01:49,257 INFO Epoch: 31\n",
            "2020-12-06 08:06:17,489 INFO Training Loss: 0.21576218627145527\n",
            "2020-12-06 08:06:17,491 INFO Training Accuracy: 92.784%\n",
            "2020-12-06 08:06:42,354 INFO Testing Loss: 0.5835640016198158\n",
            "2020-12-06 08:06:42,355 INFO Testing Accuracy: 82.13000000000001%\n",
            "2020-12-06 08:06:42,357 INFO Time: 293.0993366241455s\n",
            "2020-12-06 08:06:42,359 INFO ====================\n",
            "2020-12-06 08:06:42,360 INFO Epoch: 32\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch    32: reducing learning rate of group 0 to 1.0000e-06.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-12-06 08:11:09,083 INFO Training Loss: 0.2027820749089236\n",
            "2020-12-06 08:11:09,084 INFO Training Accuracy: 93.122%\n",
            "2020-12-06 08:11:33,893 INFO Testing Loss: 0.5767033109068871\n",
            "2020-12-06 08:11:33,894 INFO Testing Accuracy: 82.0%\n",
            "2020-12-06 08:11:33,896 INFO Time: 291.535671710968s\n",
            "2020-12-06 08:11:33,897 INFO ====================\n",
            "2020-12-06 08:11:33,898 INFO Epoch: 33\n",
            "2020-12-06 08:16:01,410 INFO Training Loss: 0.19607884756973026\n",
            "2020-12-06 08:16:01,412 INFO Training Accuracy: 93.516%\n",
            "2020-12-06 08:16:26,321 INFO Testing Loss: 0.5771302178502082\n",
            "2020-12-06 08:16:26,322 INFO Testing Accuracy: 82.44%\n",
            "2020-12-06 08:16:26,323 INFO Time: 292.4248046875s\n",
            "2020-12-06 08:16:26,325 INFO ====================\n",
            "2020-12-06 08:16:26,327 INFO Epoch: 34\n",
            "2020-12-06 08:20:52,965 INFO Training Loss: 0.19943843762892896\n",
            "2020-12-06 08:20:52,969 INFO Training Accuracy: 93.26%\n",
            "2020-12-06 08:21:17,786 INFO Testing Loss: 0.5858730652928352\n",
            "2020-12-06 08:21:17,787 INFO Testing Accuracy: 81.98%\n",
            "2020-12-06 08:21:17,788 INFO Time: 291.46179032325745s\n",
            "2020-12-06 08:21:17,790 INFO ====================\n",
            "2020-12-06 08:21:17,791 INFO Epoch: 35\n",
            "2020-12-06 08:25:44,318 INFO Training Loss: 0.19676505812369954\n",
            "2020-12-06 08:25:44,322 INFO Training Accuracy: 93.46%\n",
            "2020-12-06 08:26:09,057 INFO Testing Loss: 0.574020326435566\n",
            "2020-12-06 08:26:09,059 INFO Testing Accuracy: 82.27%\n",
            "2020-12-06 08:26:09,060 INFO Time: 291.2694640159607s\n",
            "2020-12-06 08:26:09,062 INFO ====================\n",
            "2020-12-06 08:26:09,063 INFO Epoch: 36\n",
            "2020-12-06 08:30:36,074 INFO Training Loss: 0.19726179648771922\n",
            "2020-12-06 08:30:36,076 INFO Training Accuracy: 93.41199999999999%\n",
            "2020-12-06 08:31:00,888 INFO Testing Loss: 0.5766926628351211\n",
            "2020-12-06 08:31:00,889 INFO Testing Accuracy: 82.26%\n",
            "2020-12-06 08:31:00,890 INFO Time: 291.82728600502014s\n",
            "2020-12-06 08:31:00,893 INFO ====================\n",
            "2020-12-06 08:31:00,894 INFO Epoch: 37\n",
            "2020-12-06 08:35:28,399 INFO Training Loss: 0.19660526481659515\n",
            "2020-12-06 08:35:28,401 INFO Training Accuracy: 93.638%\n",
            "2020-12-06 08:35:53,218 INFO Testing Loss: 0.5758488246798515\n",
            "2020-12-06 08:35:53,219 INFO Testing Accuracy: 82.34%\n",
            "2020-12-06 08:35:53,220 INFO Time: 292.32599329948425s\n",
            "2020-12-06 08:35:53,222 INFO ====================\n",
            "2020-12-06 08:35:53,223 INFO Epoch: 38\n",
            "2020-12-06 08:40:20,548 INFO Training Loss: 0.2001981200731319\n",
            "2020-12-06 08:40:20,553 INFO Training Accuracy: 93.352%\n",
            "2020-12-06 08:40:45,451 INFO Testing Loss: 0.5835387289524079\n",
            "2020-12-06 08:40:45,452 INFO Testing Accuracy: 82.08%\n",
            "2020-12-06 08:40:45,453 INFO Time: 292.2299394607544s\n",
            "2020-12-06 08:40:45,456 INFO ====================\n",
            "2020-12-06 08:40:45,457 INFO Epoch: 39\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch    39: reducing learning rate of group 0 to 1.0000e-07.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-12-06 08:45:13,606 INFO Training Loss: 0.19723454805667442\n",
            "2020-12-06 08:45:13,607 INFO Training Accuracy: 93.354%\n",
            "2020-12-06 08:45:38,450 INFO Testing Loss: 0.5802374640107155\n",
            "2020-12-06 08:45:38,452 INFO Testing Accuracy: 82.16%\n",
            "2020-12-06 08:45:38,453 INFO Time: 292.9964487552643s\n",
            "2020-12-06 08:45:38,454 INFO ====================\n",
            "2020-12-06 08:45:38,455 INFO Epoch: 40\n",
            "2020-12-06 08:50:06,683 INFO Training Loss: 0.19513858220232722\n",
            "2020-12-06 08:50:06,685 INFO Training Accuracy: 93.46%\n",
            "2020-12-06 08:50:31,704 INFO Testing Loss: 0.5795280051231384\n",
            "2020-12-06 08:50:31,705 INFO Testing Accuracy: 82.14%\n",
            "2020-12-06 08:50:31,706 INFO Time: 293.2511627674103s\n",
            "2020-12-06 08:50:31,707 INFO ====================\n",
            "2020-12-06 08:50:31,709 INFO Epoch: 41\n",
            "2020-12-06 08:54:59,572 INFO Training Loss: 0.1953943972773564\n",
            "2020-12-06 08:54:59,574 INFO Training Accuracy: 93.568%\n",
            "2020-12-06 08:55:24,736 INFO Testing Loss: 0.5807344195246696\n",
            "2020-12-06 08:55:24,738 INFO Testing Accuracy: 82.03%\n",
            "2020-12-06 08:55:24,739 INFO Time: 293.0300781726837s\n",
            "2020-12-06 08:55:24,740 INFO ====================\n",
            "2020-12-06 08:55:24,741 INFO Epoch: 42\n",
            "2020-12-06 08:59:53,324 INFO Training Loss: 0.19572359796070382\n",
            "2020-12-06 08:59:53,326 INFO Training Accuracy: 93.614%\n",
            "2020-12-06 09:00:18,139 INFO Testing Loss: 0.5791306051611901\n",
            "2020-12-06 09:00:18,141 INFO Testing Accuracy: 82.46%\n",
            "2020-12-06 09:00:18,142 INFO Time: 293.40071964263916s\n",
            "2020-12-06 09:00:18,143 INFO ====================\n",
            "2020-12-06 09:00:18,144 INFO Epoch: 43\n",
            "2020-12-06 09:04:45,822 INFO Training Loss: 0.19350230156460688\n",
            "2020-12-06 09:04:45,824 INFO Training Accuracy: 93.584%\n",
            "2020-12-06 09:05:10,905 INFO Testing Loss: 0.5827388301491737\n",
            "2020-12-06 09:05:10,906 INFO Testing Accuracy: 82.04%\n",
            "2020-12-06 09:05:10,907 INFO Time: 292.76294589042664s\n",
            "2020-12-06 09:05:10,909 INFO ====================\n",
            "2020-12-06 09:05:10,910 INFO Epoch: 44\n",
            "2020-12-06 09:09:38,359 INFO Training Loss: 0.19245549598160913\n",
            "2020-12-06 09:09:38,361 INFO Training Accuracy: 93.476%\n",
            "2020-12-06 09:10:03,403 INFO Testing Loss: 0.5800046321749687\n",
            "2020-12-06 09:10:03,404 INFO Testing Accuracy: 82.05%\n",
            "2020-12-06 09:10:03,406 INFO Time: 292.49600481987s\n",
            "2020-12-06 09:10:03,407 INFO ====================\n",
            "2020-12-06 09:10:03,409 INFO Epoch: 45\n",
            "2020-12-06 09:14:35,159 INFO Training Loss: 0.19122740108033884\n",
            "2020-12-06 09:14:35,161 INFO Training Accuracy: 93.696%\n",
            "2020-12-06 09:15:00,616 INFO Testing Loss: 0.5785459464788437\n",
            "2020-12-06 09:15:00,617 INFO Testing Accuracy: 82.26%\n",
            "2020-12-06 09:15:00,619 INFO Time: 297.21009254455566s\n",
            "2020-12-06 09:15:00,620 INFO ====================\n",
            "2020-12-06 09:15:00,622 INFO Epoch: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch    46: reducing learning rate of group 0 to 1.0000e-08.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-12-06 09:19:34,097 INFO Training Loss: 0.19109014490300127\n",
            "2020-12-06 09:19:34,099 INFO Training Accuracy: 93.596%\n",
            "2020-12-06 09:19:59,762 INFO Testing Loss: 0.5820698747038842\n",
            "2020-12-06 09:19:59,764 INFO Testing Accuracy: 82.19999999999999%\n",
            "2020-12-06 09:19:59,765 INFO Time: 299.1434381008148s\n",
            "2020-12-06 09:19:59,766 INFO ====================\n",
            "2020-12-06 09:19:59,768 INFO Epoch: 47\n",
            "2020-12-06 09:24:34,691 INFO Training Loss: 0.19533120825543732\n",
            "2020-12-06 09:24:34,692 INFO Training Accuracy: 93.488%\n",
            "2020-12-06 09:25:00,220 INFO Testing Loss: 0.584027693271637\n",
            "2020-12-06 09:25:00,222 INFO Testing Accuracy: 82.06%\n",
            "2020-12-06 09:25:00,223 INFO Time: 300.4550323486328s\n",
            "2020-12-06 09:25:00,224 INFO ====================\n",
            "2020-12-06 09:25:00,225 INFO Epoch: 48\n",
            "2020-12-06 09:29:38,463 INFO Training Loss: 0.19558943489857036\n",
            "2020-12-06 09:29:38,465 INFO Training Accuracy: 93.598%\n",
            "2020-12-06 09:30:04,356 INFO Testing Loss: 0.5857353708148003\n",
            "2020-12-06 09:30:04,358 INFO Testing Accuracy: 82.16%\n",
            "2020-12-06 09:30:04,360 INFO Time: 304.135249376297s\n",
            "2020-12-06 09:30:04,363 INFO ====================\n",
            "2020-12-06 09:30:04,364 INFO Epoch: 49\n",
            "2020-12-06 09:34:42,197 INFO Training Loss: 0.19519904478812766\n",
            "2020-12-06 09:34:42,199 INFO Training Accuracy: 93.542%\n",
            "2020-12-06 09:35:08,419 INFO Testing Loss: 0.580675039589405\n",
            "2020-12-06 09:35:08,420 INFO Testing Accuracy: 82.48%\n",
            "2020-12-06 09:35:08,422 INFO Time: 304.05772495269775s\n",
            "2020-12-06 09:35:08,423 INFO ====================\n",
            "2020-12-06 09:35:08,425 INFO Epoch: 50\n",
            "2020-12-06 09:39:49,150 INFO Training Loss: 0.19226666698065562\n",
            "2020-12-06 09:39:49,152 INFO Training Accuracy: 93.57799999999999%\n",
            "2020-12-06 09:40:15,394 INFO Testing Loss: 0.5806572884321213\n",
            "2020-12-06 09:40:15,398 INFO Testing Accuracy: 82.03%\n",
            "2020-12-06 09:40:15,401 INFO Time: 306.97580003738403s\n",
            "2020-12-06 09:40:15,402 INFO ====================\n",
            "2020-12-06 09:40:15,403 INFO Epoch: 51\n",
            "2020-12-06 09:44:55,651 INFO Training Loss: 0.19724774547397633\n",
            "2020-12-06 09:44:55,652 INFO Training Accuracy: 93.42%\n",
            "2020-12-06 09:45:22,077 INFO Testing Loss: 0.5838736513257027\n",
            "2020-12-06 09:45:22,079 INFO Testing Accuracy: 82.43%\n",
            "2020-12-06 09:45:22,081 INFO Time: 306.67871379852295s\n",
            "2020-12-06 09:45:22,083 INFO ====================\n",
            "2020-12-06 09:45:22,084 INFO Epoch: 52\n",
            "2020-12-06 09:50:02,189 INFO Training Loss: 0.19523921063946337\n",
            "2020-12-06 09:50:02,191 INFO Training Accuracy: 93.43%\n",
            "2020-12-06 09:50:28,308 INFO Testing Loss: 0.5826079842448234\n",
            "2020-12-06 09:50:28,310 INFO Testing Accuracy: 82.17%\n",
            "2020-12-06 09:50:28,312 INFO Time: 306.22754549980164s\n",
            "2020-12-06 09:50:28,314 INFO ====================\n",
            "2020-12-06 09:50:28,315 INFO Epoch: 53\n",
            "2020-12-06 09:55:08,996 INFO Training Loss: 0.19554131277991682\n",
            "2020-12-06 09:55:08,998 INFO Training Accuracy: 93.584%\n",
            "2020-12-06 09:55:35,344 INFO Testing Loss: 0.5814479804039001\n",
            "2020-12-06 09:55:35,346 INFO Testing Accuracy: 82.1%\n",
            "2020-12-06 09:55:35,347 INFO Time: 307.03204464912415s\n",
            "2020-12-06 09:55:35,348 INFO ====================\n",
            "2020-12-06 09:55:35,349 INFO Epoch: 54\n",
            "2020-12-06 10:00:16,767 INFO Training Loss: 0.19399277379979257\n",
            "2020-12-06 10:00:16,769 INFO Training Accuracy: 93.608%\n",
            "2020-12-06 10:00:42,836 INFO Testing Loss: 0.5875305962562561\n",
            "2020-12-06 10:00:42,837 INFO Testing Accuracy: 81.93%\n",
            "2020-12-06 10:00:42,839 INFO Time: 307.4898407459259s\n",
            "2020-12-06 10:00:42,840 INFO ====================\n",
            "2020-12-06 10:00:42,842 INFO Epoch: 55\n",
            "2020-12-06 10:05:20,497 INFO Training Loss: 0.19018373289681456\n",
            "2020-12-06 10:05:20,499 INFO Training Accuracy: 93.652%\n",
            "2020-12-06 10:05:46,668 INFO Testing Loss: 0.5796101036667823\n",
            "2020-12-06 10:05:46,669 INFO Testing Accuracy: 82.3%\n",
            "2020-12-06 10:05:46,673 INFO Time: 303.8312337398529s\n",
            "2020-12-06 10:05:46,674 INFO ====================\n",
            "2020-12-06 10:05:46,675 INFO Epoch: 56\n",
            "2020-12-06 10:10:24,317 INFO Training Loss: 0.19257681778705943\n",
            "2020-12-06 10:10:24,319 INFO Training Accuracy: 93.598%\n",
            "2020-12-06 10:10:50,151 INFO Testing Loss: 0.579796701669693\n",
            "2020-12-06 10:10:50,152 INFO Testing Accuracy: 82.04%\n",
            "2020-12-06 10:10:50,155 INFO Time: 303.4790925979614s\n",
            "2020-12-06 10:10:50,156 INFO ====================\n",
            "2020-12-06 10:10:50,157 INFO Epoch: 57\n",
            "2020-12-06 10:15:28,058 INFO Training Loss: 0.192351109383966\n",
            "2020-12-06 10:15:28,060 INFO Training Accuracy: 93.58%\n",
            "2020-12-06 10:15:53,640 INFO Testing Loss: 0.5779394328594207\n",
            "2020-12-06 10:15:53,642 INFO Testing Accuracy: 82.14%\n",
            "2020-12-06 10:15:53,643 INFO Time: 303.4861145019531s\n",
            "2020-12-06 10:15:53,644 INFO ====================\n",
            "2020-12-06 10:15:53,646 INFO Epoch: 58\n",
            "2020-12-06 10:20:29,040 INFO Training Loss: 0.1938058226119222\n",
            "2020-12-06 10:20:29,042 INFO Training Accuracy: 93.552%\n",
            "2020-12-06 10:20:54,620 INFO Testing Loss: 0.5828273022174835\n",
            "2020-12-06 10:20:54,622 INFO Testing Accuracy: 82.12%\n",
            "2020-12-06 10:20:54,623 INFO Time: 300.97667956352234s\n",
            "2020-12-06 10:20:54,624 INFO ====================\n",
            "2020-12-06 10:20:54,626 INFO Epoch: 59\n",
            "2020-12-06 10:25:30,690 INFO Training Loss: 0.19511704667068808\n",
            "2020-12-06 10:25:30,691 INFO Training Accuracy: 93.486%\n",
            "2020-12-06 10:25:56,429 INFO Testing Loss: 0.583826306462288\n",
            "2020-12-06 10:25:56,431 INFO Testing Accuracy: 82.12%\n",
            "2020-12-06 10:25:56,432 INFO Time: 301.8060760498047s\n",
            "2020-12-06 10:25:56,433 INFO ====================\n",
            "2020-12-06 10:25:56,920 INFO Seed: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-12-06 10:25:58,916 INFO Epoch: 0\n",
            "2020-12-06 10:30:23,156 INFO Training Loss: 1.9525922744170479\n",
            "2020-12-06 10:30:23,158 INFO Training Accuracy: 27.526%\n",
            "2020-12-06 10:30:48,168 INFO Testing Loss: 1.8094338059425354\n",
            "2020-12-06 10:30:48,169 INFO Testing Accuracy: 33.26%\n",
            "2020-12-06 10:30:48,170 INFO Time: 289.2539894580841s\n",
            "2020-12-06 10:30:48,171 INFO ====================\n",
            "2020-12-06 10:30:48,172 INFO Epoch: 1\n",
            "2020-12-06 10:35:12,342 INFO Training Loss: 1.6938682367734592\n",
            "2020-12-06 10:35:12,345 INFO Training Accuracy: 37.424%\n",
            "2020-12-06 10:35:37,628 INFO Testing Loss: 1.5689177632331848\n",
            "2020-12-06 10:35:37,630 INFO Testing Accuracy: 41.71%\n",
            "2020-12-06 10:35:37,631 INFO Time: 289.4592785835266s\n",
            "2020-12-06 10:35:37,632 INFO ====================\n",
            "2020-12-06 10:35:37,633 INFO Epoch: 2\n",
            "2020-12-06 10:40:04,106 INFO Training Loss: 1.5616890612770529\n",
            "2020-12-06 10:40:04,108 INFO Training Accuracy: 42.356%\n",
            "2020-12-06 10:40:29,401 INFO Testing Loss: 1.5161695289611816\n",
            "2020-12-06 10:40:29,403 INFO Testing Accuracy: 44.91%\n",
            "2020-12-06 10:40:29,404 INFO Time: 291.7708921432495s\n",
            "2020-12-06 10:40:29,405 INFO ====================\n",
            "2020-12-06 10:40:29,406 INFO Epoch: 3\n",
            "2020-12-06 10:44:56,212 INFO Training Loss: 1.4700383124753946\n",
            "2020-12-06 10:44:56,214 INFO Training Accuracy: 46.202%\n",
            "2020-12-06 10:45:21,829 INFO Testing Loss: 1.3523601186275482\n",
            "2020-12-06 10:45:21,831 INFO Testing Accuracy: 50.370000000000005%\n",
            "2020-12-06 10:45:21,832 INFO Time: 292.42544651031494s\n",
            "2020-12-06 10:45:21,835 INFO ====================\n",
            "2020-12-06 10:45:21,836 INFO Epoch: 4\n",
            "2020-12-06 10:49:48,137 INFO Training Loss: 1.3672069759320116\n",
            "2020-12-06 10:49:48,139 INFO Training Accuracy: 50.482000000000006%\n",
            "2020-12-06 10:50:13,484 INFO Testing Loss: 1.2715969330072403\n",
            "2020-12-06 10:50:13,485 INFO Testing Accuracy: 53.73%\n",
            "2020-12-06 10:50:13,488 INFO Time: 291.6519205570221s\n",
            "2020-12-06 10:50:13,490 INFO ====================\n",
            "2020-12-06 10:50:13,490 INFO Epoch: 5\n",
            "2020-12-06 10:54:39,858 INFO Training Loss: 1.2974702032935588\n",
            "2020-12-06 10:54:39,860 INFO Training Accuracy: 53.11%\n",
            "2020-12-06 10:55:05,268 INFO Testing Loss: 1.1979600983858107\n",
            "2020-12-06 10:55:05,269 INFO Testing Accuracy: 56.68%\n",
            "2020-12-06 10:55:05,271 INFO Time: 291.78018617630005s\n",
            "2020-12-06 10:55:05,272 INFO ====================\n",
            "2020-12-06 10:55:05,274 INFO Epoch: 6\n",
            "2020-12-06 10:59:31,370 INFO Training Loss: 1.2014302745499574\n",
            "2020-12-06 10:59:31,371 INFO Training Accuracy: 56.85%\n",
            "2020-12-06 10:59:56,510 INFO Testing Loss: 1.1290744680166245\n",
            "2020-12-06 10:59:56,512 INFO Testing Accuracy: 59.56%\n",
            "2020-12-06 10:59:56,514 INFO Time: 291.2400426864624s\n",
            "2020-12-06 10:59:56,516 INFO ====================\n",
            "2020-12-06 10:59:56,517 INFO Epoch: 7\n",
            "2020-12-06 11:04:22,606 INFO Training Loss: 1.12727587835868\n",
            "2020-12-06 11:04:22,607 INFO Training Accuracy: 59.56%\n",
            "2020-12-06 11:04:47,910 INFO Testing Loss: 1.1261226761341094\n",
            "2020-12-06 11:04:47,912 INFO Testing Accuracy: 60.4%\n",
            "2020-12-06 11:04:47,914 INFO Time: 291.39768147468567s\n",
            "2020-12-06 11:04:47,916 INFO ====================\n",
            "2020-12-06 11:04:47,917 INFO Epoch: 8\n",
            "2020-12-06 11:09:14,997 INFO Training Loss: 1.0593071130230605\n",
            "2020-12-06 11:09:14,998 INFO Training Accuracy: 62.364%\n",
            "2020-12-06 11:09:40,461 INFO Testing Loss: 1.0028234672546388\n",
            "2020-12-06 11:09:40,462 INFO Testing Accuracy: 64.49000000000001%\n",
            "2020-12-06 11:09:40,464 INFO Time: 292.5473141670227s\n",
            "2020-12-06 11:09:40,466 INFO ====================\n",
            "2020-12-06 11:09:40,467 INFO Epoch: 9\n",
            "2020-12-06 11:14:07,387 INFO Training Loss: 0.9903585084563936\n",
            "2020-12-06 11:14:07,389 INFO Training Accuracy: 65.01%\n",
            "2020-12-06 11:14:32,829 INFO Testing Loss: 1.0036801952123642\n",
            "2020-12-06 11:14:32,831 INFO Testing Accuracy: 64.55%\n",
            "2020-12-06 11:14:32,832 INFO Time: 292.36565709114075s\n",
            "2020-12-06 11:14:32,834 INFO ====================\n",
            "2020-12-06 11:14:32,835 INFO Epoch: 10\n",
            "2020-12-06 11:18:59,905 INFO Training Loss: 0.931885484691776\n",
            "2020-12-06 11:18:59,907 INFO Training Accuracy: 67.23%\n",
            "2020-12-06 11:19:25,561 INFO Testing Loss: 0.9410354149341583\n",
            "2020-12-06 11:19:25,563 INFO Testing Accuracy: 67.07%\n",
            "2020-12-06 11:19:25,564 INFO Time: 292.72861528396606s\n",
            "2020-12-06 11:19:25,565 INFO ====================\n",
            "2020-12-06 11:19:25,566 INFO Epoch: 11\n",
            "2020-12-06 11:23:53,029 INFO Training Loss: 0.8813772745754408\n",
            "2020-12-06 11:23:53,031 INFO Training Accuracy: 68.746%\n",
            "2020-12-06 11:24:18,546 INFO Testing Loss: 0.9241955524682999\n",
            "2020-12-06 11:24:18,548 INFO Testing Accuracy: 67.61%\n",
            "2020-12-06 11:24:18,549 INFO Time: 292.9829812049866s\n",
            "2020-12-06 11:24:18,551 INFO ====================\n",
            "2020-12-06 11:24:18,552 INFO Epoch: 12\n",
            "2020-12-06 11:28:52,418 INFO Training Loss: 0.8246849703666804\n",
            "2020-12-06 11:28:52,420 INFO Training Accuracy: 71.088%\n",
            "2020-12-06 11:29:17,733 INFO Testing Loss: 0.8420880198478699\n",
            "2020-12-06 11:29:17,735 INFO Testing Accuracy: 70.62%\n",
            "2020-12-06 11:29:17,736 INFO Time: 299.1836133003235s\n",
            "2020-12-06 11:29:17,737 INFO ====================\n",
            "2020-12-06 11:29:17,739 INFO Epoch: 13\n",
            "2020-12-06 11:33:42,273 INFO Training Loss: 0.7782211707681036\n",
            "2020-12-06 11:33:42,275 INFO Training Accuracy: 72.494%\n",
            "2020-12-06 11:34:07,806 INFO Testing Loss: 0.8028362694382668\n",
            "2020-12-06 11:34:07,808 INFO Testing Accuracy: 72.57000000000001%\n",
            "2020-12-06 11:34:07,809 INFO Time: 290.06991839408875s\n",
            "2020-12-06 11:34:07,811 INFO ====================\n",
            "2020-12-06 11:34:07,812 INFO Epoch: 14\n",
            "2020-12-06 11:38:33,264 INFO Training Loss: 0.7215816037886588\n",
            "2020-12-06 11:38:33,265 INFO Training Accuracy: 74.482%\n",
            "2020-12-06 11:38:58,484 INFO Testing Loss: 0.7941164135932922\n",
            "2020-12-06 11:38:58,486 INFO Testing Accuracy: 72.39999999999999%\n",
            "2020-12-06 11:38:58,488 INFO Time: 290.6762092113495s\n",
            "2020-12-06 11:38:58,490 INFO ====================\n",
            "2020-12-06 11:38:58,491 INFO Epoch: 15\n",
            "2020-12-06 11:43:23,958 INFO Training Loss: 0.6897984587627909\n",
            "2020-12-06 11:43:23,960 INFO Training Accuracy: 75.644%\n",
            "2020-12-06 11:43:49,363 INFO Testing Loss: 0.7534530001878739\n",
            "2020-12-06 11:43:49,365 INFO Testing Accuracy: 74.09%\n",
            "2020-12-06 11:43:49,366 INFO Time: 290.8744387626648s\n",
            "2020-12-06 11:43:49,367 INFO ====================\n",
            "2020-12-06 11:43:49,369 INFO Epoch: 16\n",
            "2020-12-06 11:48:14,147 INFO Training Loss: 0.6376813399364881\n",
            "2020-12-06 11:48:14,149 INFO Training Accuracy: 77.738%\n",
            "2020-12-06 11:48:39,468 INFO Testing Loss: 0.7231152242422104\n",
            "2020-12-06 11:48:39,471 INFO Testing Accuracy: 75.37%\n",
            "2020-12-06 11:48:39,472 INFO Time: 290.1034665107727s\n",
            "2020-12-06 11:48:39,475 INFO ====================\n",
            "2020-12-06 11:48:39,477 INFO Epoch: 17\n",
            "2020-12-06 11:53:03,869 INFO Training Loss: 0.6002438143086251\n",
            "2020-12-06 11:53:03,870 INFO Training Accuracy: 78.802%\n",
            "2020-12-06 11:53:29,090 INFO Testing Loss: 0.7091092362999916\n",
            "2020-12-06 11:53:29,092 INFO Testing Accuracy: 76.11%\n",
            "2020-12-06 11:53:29,094 INFO Time: 289.6168644428253s\n",
            "2020-12-06 11:53:29,095 INFO ====================\n",
            "2020-12-06 11:53:29,095 INFO Epoch: 18\n",
            "2020-12-06 11:57:53,631 INFO Training Loss: 0.5641012478362569\n",
            "2020-12-06 11:57:53,633 INFO Training Accuracy: 79.904%\n",
            "2020-12-06 11:58:18,749 INFO Testing Loss: 0.6892048308253288\n",
            "2020-12-06 11:58:18,751 INFO Testing Accuracy: 76.78%\n",
            "2020-12-06 11:58:18,752 INFO Time: 289.6567814350128s\n",
            "2020-12-06 11:58:18,753 INFO ====================\n",
            "2020-12-06 11:58:18,754 INFO Epoch: 19\n",
            "2020-12-06 12:02:43,745 INFO Training Loss: 0.5276198994625559\n",
            "2020-12-06 12:02:43,748 INFO Training Accuracy: 81.584%\n",
            "2020-12-06 12:03:08,867 INFO Testing Loss: 0.6947659265995025\n",
            "2020-12-06 12:03:08,869 INFO Testing Accuracy: 76.86%\n",
            "2020-12-06 12:03:08,870 INFO Time: 290.11608362197876s\n",
            "2020-12-06 12:03:08,872 INFO ====================\n",
            "2020-12-06 12:03:08,873 INFO Epoch: 20\n",
            "2020-12-06 12:07:33,259 INFO Training Loss: 0.4899715145530603\n",
            "2020-12-06 12:07:33,261 INFO Training Accuracy: 82.696%\n",
            "2020-12-06 12:07:58,418 INFO Testing Loss: 0.6918542736768722\n",
            "2020-12-06 12:07:58,420 INFO Testing Accuracy: 77.18%\n",
            "2020-12-06 12:07:58,421 INFO Time: 289.54775762557983s\n",
            "2020-12-06 12:07:58,422 INFO ====================\n",
            "2020-12-06 12:07:58,423 INFO Epoch: 21\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch    21: reducing learning rate of group 0 to 1.0000e-05.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-12-06 12:12:22,573 INFO Training Loss: 0.387848393272256\n",
            "2020-12-06 12:12:22,575 INFO Training Accuracy: 86.72%\n",
            "2020-12-06 12:12:47,848 INFO Testing Loss: 0.5967134165763855\n",
            "2020-12-06 12:12:47,849 INFO Testing Accuracy: 80.07%\n",
            "2020-12-06 12:12:47,850 INFO Time: 289.42720794677734s\n",
            "2020-12-06 12:12:47,851 INFO ====================\n",
            "2020-12-06 12:12:47,853 INFO Epoch: 22\n",
            "2020-12-06 12:17:11,724 INFO Training Loss: 0.35876472637324075\n",
            "2020-12-06 12:17:11,727 INFO Training Accuracy: 87.656%\n",
            "2020-12-06 12:17:36,962 INFO Testing Loss: 0.6025083899497986\n",
            "2020-12-06 12:17:36,963 INFO Testing Accuracy: 80.2%\n",
            "2020-12-06 12:17:36,965 INFO Time: 289.11197233200073s\n",
            "2020-12-06 12:17:36,965 INFO ====================\n",
            "2020-12-06 12:17:36,966 INFO Epoch: 23\n",
            "2020-12-06 12:22:00,708 INFO Training Loss: 0.3444847811747085\n",
            "2020-12-06 12:22:00,710 INFO Training Accuracy: 88.08200000000001%\n",
            "2020-12-06 12:22:25,917 INFO Testing Loss: 0.5976805928349495\n",
            "2020-12-06 12:22:25,919 INFO Testing Accuracy: 80.23%\n",
            "2020-12-06 12:22:25,920 INFO Time: 288.95351791381836s\n",
            "2020-12-06 12:22:25,921 INFO ====================\n",
            "2020-12-06 12:22:25,922 INFO Epoch: 24\n",
            "2020-12-06 12:26:49,395 INFO Training Loss: 0.3285572718247733\n",
            "2020-12-06 12:26:49,397 INFO Training Accuracy: 88.774%\n",
            "2020-12-06 12:27:14,678 INFO Testing Loss: 0.5988547265529632\n",
            "2020-12-06 12:27:14,679 INFO Testing Accuracy: 80.58999999999999%\n",
            "2020-12-06 12:27:14,681 INFO Time: 288.7584283351898s\n",
            "2020-12-06 12:27:14,682 INFO ====================\n",
            "2020-12-06 12:27:14,683 INFO Epoch: 25\n",
            "2020-12-06 12:31:38,130 INFO Training Loss: 0.32350143683535976\n",
            "2020-12-06 12:31:38,132 INFO Training Accuracy: 88.898%\n",
            "2020-12-06 12:32:03,303 INFO Testing Loss: 0.5997557803988457\n",
            "2020-12-06 12:32:03,305 INFO Testing Accuracy: 80.61%\n",
            "2020-12-06 12:32:03,306 INFO Time: 288.6235728263855s\n",
            "2020-12-06 12:32:03,307 INFO ====================\n",
            "2020-12-06 12:32:03,309 INFO Epoch: 26\n",
            "2020-12-06 12:36:26,259 INFO Training Loss: 0.31218509627577595\n",
            "2020-12-06 12:36:26,261 INFO Training Accuracy: 89.27000000000001%\n",
            "2020-12-06 12:36:50,938 INFO Testing Loss: 0.606475625038147\n",
            "2020-12-06 12:36:50,939 INFO Testing Accuracy: 80.58999999999999%\n",
            "2020-12-06 12:36:50,941 INFO Time: 287.6317596435547s\n",
            "2020-12-06 12:36:50,942 INFO ====================\n",
            "2020-12-06 12:36:50,944 INFO Epoch: 27\n",
            "2020-12-06 12:41:13,180 INFO Training Loss: 0.30398871343763895\n",
            "2020-12-06 12:41:13,181 INFO Training Accuracy: 89.526%\n",
            "2020-12-06 12:41:38,417 INFO Testing Loss: 0.6181441804766655\n",
            "2020-12-06 12:41:38,419 INFO Testing Accuracy: 80.06%\n",
            "2020-12-06 12:41:38,420 INFO Time: 287.47649788856506s\n",
            "2020-12-06 12:41:38,422 INFO ====================\n",
            "2020-12-06 12:41:38,423 INFO Epoch: 28\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch    28: reducing learning rate of group 0 to 1.0000e-06.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-12-06 12:46:02,216 INFO Training Loss: 0.28770225965763296\n",
            "2020-12-06 12:46:02,218 INFO Training Accuracy: 90.202%\n",
            "2020-12-06 12:46:27,293 INFO Testing Loss: 0.6119691866636277\n",
            "2020-12-06 12:46:27,294 INFO Testing Accuracy: 80.44%\n",
            "2020-12-06 12:46:27,296 INFO Time: 288.87260389328003s\n",
            "2020-12-06 12:46:27,297 INFO ====================\n",
            "2020-12-06 12:46:27,299 INFO Epoch: 29\n",
            "2020-12-06 12:50:50,531 INFO Training Loss: 0.2870161387392932\n",
            "2020-12-06 12:50:50,533 INFO Training Accuracy: 90.076%\n",
            "2020-12-06 12:51:15,558 INFO Testing Loss: 0.6057143363356591\n",
            "2020-12-06 12:51:15,560 INFO Testing Accuracy: 80.58999999999999%\n",
            "2020-12-06 12:51:15,561 INFO Time: 288.26228523254395s\n",
            "2020-12-06 12:51:15,563 INFO ====================\n",
            "2020-12-06 12:51:15,564 INFO Epoch: 30\n",
            "2020-12-06 12:55:38,467 INFO Training Loss: 0.2849969049853742\n",
            "2020-12-06 12:55:38,468 INFO Training Accuracy: 90.38000000000001%\n",
            "2020-12-06 12:56:03,548 INFO Testing Loss: 0.6098162513971329\n",
            "2020-12-06 12:56:03,549 INFO Testing Accuracy: 80.22%\n",
            "2020-12-06 12:56:03,550 INFO Time: 287.98576045036316s\n",
            "2020-12-06 12:56:03,552 INFO ====================\n",
            "2020-12-06 12:56:03,554 INFO Epoch: 31\n",
            "2020-12-06 13:00:26,125 INFO Training Loss: 0.28642768845381333\n",
            "2020-12-06 13:00:26,127 INFO Training Accuracy: 90.18599999999999%\n",
            "2020-12-06 13:00:51,033 INFO Testing Loss: 0.6119795289635658\n",
            "2020-12-06 13:00:51,035 INFO Testing Accuracy: 80.53%\n",
            "2020-12-06 13:00:51,036 INFO Time: 287.48214054107666s\n",
            "2020-12-06 13:00:51,038 INFO ====================\n",
            "2020-12-06 13:00:51,038 INFO Epoch: 32\n",
            "2020-12-06 13:05:14,574 INFO Training Loss: 0.2827609655878428\n",
            "2020-12-06 13:05:14,576 INFO Training Accuracy: 90.38000000000001%\n",
            "2020-12-06 13:05:39,843 INFO Testing Loss: 0.6122041094303131\n",
            "2020-12-06 13:05:39,845 INFO Testing Accuracy: 80.45%\n",
            "2020-12-06 13:05:39,847 INFO Time: 288.8081097602844s\n",
            "2020-12-06 13:05:39,848 INFO ====================\n",
            "2020-12-06 13:05:39,850 INFO Epoch: 33\n",
            "2020-12-06 13:10:04,941 INFO Training Loss: 0.2836087028998548\n",
            "2020-12-06 13:10:04,942 INFO Training Accuracy: 90.208%\n",
            "2020-12-06 13:10:29,959 INFO Testing Loss: 0.6099918872117996\n",
            "2020-12-06 13:10:29,961 INFO Testing Accuracy: 80.81%\n",
            "2020-12-06 13:10:29,962 INFO Time: 290.11241936683655s\n",
            "2020-12-06 13:10:29,964 INFO ====================\n",
            "2020-12-06 13:10:29,965 INFO Epoch: 34\n",
            "2020-12-06 13:14:52,911 INFO Training Loss: 0.28381932185738895\n",
            "2020-12-06 13:14:52,913 INFO Training Accuracy: 90.428%\n",
            "2020-12-06 13:15:18,081 INFO Testing Loss: 0.6138257890939712\n",
            "2020-12-06 13:15:18,083 INFO Testing Accuracy: 80.87%\n",
            "2020-12-06 13:15:18,084 INFO Time: 288.11956310272217s\n",
            "2020-12-06 13:15:18,086 INFO ====================\n",
            "2020-12-06 13:15:18,087 INFO Epoch: 35\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch    35: reducing learning rate of group 0 to 1.0000e-07.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-12-06 13:19:40,531 INFO Training Loss: 0.2819283233807825\n",
            "2020-12-06 13:19:40,533 INFO Training Accuracy: 90.342%\n",
            "2020-12-06 13:20:05,444 INFO Testing Loss: 0.6071100416779518\n",
            "2020-12-06 13:20:05,446 INFO Testing Accuracy: 80.88%\n",
            "2020-12-06 13:20:05,448 INFO Time: 287.3606152534485s\n",
            "2020-12-06 13:20:05,450 INFO ====================\n",
            "2020-12-06 13:20:05,451 INFO Epoch: 36\n",
            "2020-12-06 13:24:28,960 INFO Training Loss: 0.28225772170459523\n",
            "2020-12-06 13:24:28,962 INFO Training Accuracy: 90.386%\n",
            "2020-12-06 13:24:54,407 INFO Testing Loss: 0.6114939913153649\n",
            "2020-12-06 13:24:54,409 INFO Testing Accuracy: 80.78999999999999%\n",
            "2020-12-06 13:24:54,411 INFO Time: 288.95995450019836s\n",
            "2020-12-06 13:24:54,412 INFO ====================\n",
            "2020-12-06 13:24:54,413 INFO Epoch: 37\n",
            "2020-12-06 13:29:19,539 INFO Training Loss: 0.277653476733076\n",
            "2020-12-06 13:29:19,541 INFO Training Accuracy: 90.352%\n",
            "2020-12-06 13:29:44,989 INFO Testing Loss: 0.6092450070381165\n",
            "2020-12-06 13:29:44,990 INFO Testing Accuracy: 80.42%\n",
            "2020-12-06 13:29:44,993 INFO Time: 290.58001041412354s\n",
            "2020-12-06 13:29:44,994 INFO ====================\n",
            "2020-12-06 13:29:44,995 INFO Epoch: 38\n",
            "2020-12-06 13:34:09,911 INFO Training Loss: 0.2765333852194764\n",
            "2020-12-06 13:34:09,913 INFO Training Accuracy: 90.618%\n",
            "2020-12-06 13:34:35,377 INFO Testing Loss: 0.6145712020993233\n",
            "2020-12-06 13:34:35,379 INFO Testing Accuracy: 80.76%\n",
            "2020-12-06 13:34:35,381 INFO Time: 290.3857800960541s\n",
            "2020-12-06 13:34:35,382 INFO ====================\n",
            "2020-12-06 13:34:35,383 INFO Epoch: 39\n",
            "2020-12-06 13:38:59,928 INFO Training Loss: 0.2807464511955486\n",
            "2020-12-06 13:38:59,930 INFO Training Accuracy: 90.46%\n",
            "2020-12-06 13:39:25,378 INFO Testing Loss: 0.6043088805675506\n",
            "2020-12-06 13:39:25,380 INFO Testing Accuracy: 80.87%\n",
            "2020-12-06 13:39:25,381 INFO Time: 289.9975824356079s\n",
            "2020-12-06 13:39:25,382 INFO ====================\n",
            "2020-12-06 13:39:25,384 INFO Epoch: 40\n",
            "2020-12-06 13:43:49,775 INFO Training Loss: 0.2766377611081009\n",
            "2020-12-06 13:43:49,777 INFO Training Accuracy: 90.574%\n",
            "2020-12-06 13:44:15,013 INFO Testing Loss: 0.6143729230761528\n",
            "2020-12-06 13:44:15,014 INFO Testing Accuracy: 80.41%\n",
            "2020-12-06 13:44:15,015 INFO Time: 289.6313121318817s\n",
            "2020-12-06 13:44:15,017 INFO ====================\n",
            "2020-12-06 13:44:15,018 INFO Epoch: 41\n",
            "2020-12-06 13:48:39,471 INFO Training Loss: 0.279169834673862\n",
            "2020-12-06 13:48:39,473 INFO Training Accuracy: 90.42999999999999%\n",
            "2020-12-06 13:49:04,367 INFO Testing Loss: 0.6134175962209701\n",
            "2020-12-06 13:49:04,368 INFO Testing Accuracy: 80.73%\n",
            "2020-12-06 13:49:04,373 INFO Time: 289.3547668457031s\n",
            "2020-12-06 13:49:04,374 INFO ====================\n",
            "2020-12-06 13:49:04,374 INFO Epoch: 42\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch    42: reducing learning rate of group 0 to 1.0000e-08.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-12-06 13:53:25,210 INFO Training Loss: 0.27853719802463756\n",
            "2020-12-06 13:53:25,213 INFO Training Accuracy: 90.52799999999999%\n",
            "2020-12-06 13:53:50,101 INFO Testing Loss: 0.6104081317782402\n",
            "2020-12-06 13:53:50,103 INFO Testing Accuracy: 80.58%\n",
            "2020-12-06 13:53:50,104 INFO Time: 285.7297966480255s\n",
            "2020-12-06 13:53:50,106 INFO ====================\n",
            "2020-12-06 13:53:50,107 INFO Epoch: 43\n",
            "2020-12-06 13:58:09,911 INFO Training Loss: 0.2820942757836998\n",
            "2020-12-06 13:58:09,913 INFO Training Accuracy: 90.318%\n",
            "2020-12-06 13:58:34,735 INFO Testing Loss: 0.608096388578415\n",
            "2020-12-06 13:58:34,737 INFO Testing Accuracy: 80.43%\n",
            "2020-12-06 13:58:34,738 INFO Time: 284.6313679218292s\n",
            "2020-12-06 13:58:34,739 INFO ====================\n",
            "2020-12-06 13:58:34,741 INFO Epoch: 44\n",
            "2020-12-06 14:02:55,704 INFO Training Loss: 0.2802696923541901\n",
            "2020-12-06 14:02:55,705 INFO Training Accuracy: 90.456%\n",
            "2020-12-06 14:03:20,765 INFO Testing Loss: 0.6095640769600869\n",
            "2020-12-06 14:03:20,767 INFO Testing Accuracy: 80.45%\n",
            "2020-12-06 14:03:20,769 INFO Time: 286.02752327919006s\n",
            "2020-12-06 14:03:20,771 INFO ====================\n",
            "2020-12-06 14:03:20,773 INFO Epoch: 45\n",
            "2020-12-06 14:07:40,673 INFO Training Loss: 0.278750831856752\n",
            "2020-12-06 14:07:40,675 INFO Training Accuracy: 90.582%\n",
            "2020-12-06 14:08:05,304 INFO Testing Loss: 0.6172255685925484\n",
            "2020-12-06 14:08:05,305 INFO Testing Accuracy: 80.41%\n",
            "2020-12-06 14:08:05,308 INFO Time: 284.5354187488556s\n",
            "2020-12-06 14:08:05,309 INFO ====================\n",
            "2020-12-06 14:08:05,311 INFO Epoch: 46\n",
            "2020-12-06 14:12:25,193 INFO Training Loss: 0.27589140630439113\n",
            "2020-12-06 14:12:25,195 INFO Training Accuracy: 90.63799999999999%\n",
            "2020-12-06 14:12:49,920 INFO Testing Loss: 0.605599293410778\n",
            "2020-12-06 14:12:49,922 INFO Testing Accuracy: 80.72%\n",
            "2020-12-06 14:12:49,924 INFO Time: 284.61353611946106s\n",
            "2020-12-06 14:12:49,925 INFO ====================\n",
            "2020-12-06 14:12:49,926 INFO Epoch: 47\n",
            "2020-12-06 14:17:09,681 INFO Training Loss: 0.27863839966104464\n",
            "2020-12-06 14:17:09,683 INFO Training Accuracy: 90.48%\n",
            "2020-12-06 14:17:34,611 INFO Testing Loss: 0.6109094455838203\n",
            "2020-12-06 14:17:34,613 INFO Testing Accuracy: 80.58999999999999%\n",
            "2020-12-06 14:17:34,615 INFO Time: 284.68853521347046s\n",
            "2020-12-06 14:17:34,617 INFO ====================\n",
            "2020-12-06 14:17:34,618 INFO Epoch: 48\n",
            "2020-12-06 14:21:56,951 INFO Training Loss: 0.2811270129421483\n",
            "2020-12-06 14:21:56,953 INFO Training Accuracy: 90.38199999999999%\n",
            "2020-12-06 14:22:21,920 INFO Testing Loss: 0.613294347524643\n",
            "2020-12-06 14:22:21,922 INFO Testing Accuracy: 80.47%\n",
            "2020-12-06 14:22:21,924 INFO Time: 287.3068039417267s\n",
            "2020-12-06 14:22:21,926 INFO ====================\n",
            "2020-12-06 14:22:21,927 INFO Epoch: 49\n",
            "2020-12-06 14:26:43,898 INFO Training Loss: 0.28055700930335636\n",
            "2020-12-06 14:26:43,899 INFO Training Accuracy: 90.534%\n",
            "2020-12-06 14:27:08,693 INFO Testing Loss: 0.6083677285909652\n",
            "2020-12-06 14:27:08,695 INFO Testing Accuracy: 80.47%\n",
            "2020-12-06 14:27:08,696 INFO Time: 286.7689015865326s\n",
            "2020-12-06 14:27:08,698 INFO ====================\n",
            "2020-12-06 14:27:08,700 INFO Epoch: 50\n",
            "2020-12-06 14:31:28,540 INFO Training Loss: 0.2778284530276838\n",
            "2020-12-06 14:31:28,541 INFO Training Accuracy: 90.486%\n",
            "2020-12-06 14:31:53,192 INFO Testing Loss: 0.6127749606966972\n",
            "2020-12-06 14:31:53,194 INFO Testing Accuracy: 80.78999999999999%\n",
            "2020-12-06 14:31:53,195 INFO Time: 284.49497509002686s\n",
            "2020-12-06 14:31:53,196 INFO ====================\n",
            "2020-12-06 14:31:53,197 INFO Epoch: 51\n",
            "2020-12-06 14:36:12,512 INFO Training Loss: 0.27902562207425646\n",
            "2020-12-06 14:36:12,515 INFO Training Accuracy: 90.51599999999999%\n",
            "2020-12-06 14:36:37,464 INFO Testing Loss: 0.6101747685670853\n",
            "2020-12-06 14:36:37,465 INFO Testing Accuracy: 80.89%\n",
            "2020-12-06 14:36:37,467 INFO Time: 284.2696964740753s\n",
            "2020-12-06 14:36:37,469 INFO ====================\n",
            "2020-12-06 14:36:37,470 INFO Epoch: 52\n",
            "2020-12-06 14:41:03,254 INFO Training Loss: 0.2816347746211854\n",
            "2020-12-06 14:41:03,258 INFO Training Accuracy: 90.334%\n",
            "2020-12-06 14:41:28,374 INFO Testing Loss: 0.6077869749069214\n",
            "2020-12-06 14:41:28,375 INFO Testing Accuracy: 80.53%\n",
            "2020-12-06 14:41:28,377 INFO Time: 290.90680980682373s\n",
            "2020-12-06 14:41:28,378 INFO ====================\n",
            "2020-12-06 14:41:28,379 INFO Epoch: 53\n",
            "2020-12-06 14:45:48,865 INFO Training Loss: 0.27900737916569573\n",
            "2020-12-06 14:45:48,867 INFO Training Accuracy: 90.424%\n",
            "2020-12-06 14:46:13,604 INFO Testing Loss: 0.6097615325450897\n",
            "2020-12-06 14:46:13,605 INFO Testing Accuracy: 80.67%\n",
            "2020-12-06 14:46:13,606 INFO Time: 285.2268764972687s\n",
            "2020-12-06 14:46:13,608 INFO ====================\n",
            "2020-12-06 14:46:13,610 INFO Epoch: 54\n",
            "2020-12-06 14:50:33,597 INFO Training Loss: 0.2773369553753787\n",
            "2020-12-06 14:50:33,598 INFO Training Accuracy: 90.604%\n",
            "2020-12-06 14:50:58,372 INFO Testing Loss: 0.6049368581175805\n",
            "2020-12-06 14:50:58,373 INFO Testing Accuracy: 80.83%\n",
            "2020-12-06 14:50:58,374 INFO Time: 284.7649805545807s\n",
            "2020-12-06 14:50:58,376 INFO ====================\n",
            "2020-12-06 14:50:58,378 INFO Epoch: 55\n",
            "2020-12-06 14:55:18,101 INFO Training Loss: 0.27845438994714977\n",
            "2020-12-06 14:55:18,103 INFO Training Accuracy: 90.44200000000001%\n",
            "2020-12-06 14:55:42,884 INFO Testing Loss: 0.6115478360652924\n",
            "2020-12-06 14:55:42,885 INFO Testing Accuracy: 80.82000000000001%\n",
            "2020-12-06 14:55:42,886 INFO Time: 284.5085005760193s\n",
            "2020-12-06 14:55:42,887 INFO ====================\n",
            "2020-12-06 14:55:42,889 INFO Epoch: 56\n",
            "2020-12-06 15:00:00,512 INFO Training Loss: 0.27508289300267347\n",
            "2020-12-06 15:00:00,513 INFO Training Accuracy: 90.736%\n",
            "2020-12-06 15:00:25,011 INFO Testing Loss: 0.6101453340053559\n",
            "2020-12-06 15:00:25,013 INFO Testing Accuracy: 80.54%\n",
            "2020-12-06 15:00:25,015 INFO Time: 282.1261112689972s\n",
            "2020-12-06 15:00:25,016 INFO ====================\n",
            "2020-12-06 15:00:25,017 INFO Epoch: 57\n",
            "2020-12-06 15:04:39,715 INFO Training Loss: 0.2773243510128592\n",
            "2020-12-06 15:04:39,717 INFO Training Accuracy: 90.546%\n",
            "2020-12-06 15:05:03,976 INFO Testing Loss: 0.6079204598069191\n",
            "2020-12-06 15:05:03,977 INFO Testing Accuracy: 80.62%\n",
            "2020-12-06 15:05:03,979 INFO Time: 278.96183919906616s\n",
            "2020-12-06 15:05:03,981 INFO ====================\n",
            "2020-12-06 15:05:03,982 INFO Epoch: 58\n",
            "2020-12-06 15:09:20,853 INFO Training Loss: 0.277956429078146\n",
            "2020-12-06 15:09:20,854 INFO Training Accuracy: 90.46%\n",
            "2020-12-06 15:09:45,589 INFO Testing Loss: 0.6160510820150376\n",
            "2020-12-06 15:09:45,591 INFO Testing Accuracy: 80.84%\n",
            "2020-12-06 15:09:45,592 INFO Time: 281.61027431488037s\n",
            "2020-12-06 15:09:45,594 INFO ====================\n",
            "2020-12-06 15:09:45,595 INFO Epoch: 59\n",
            "2020-12-06 15:14:05,265 INFO Training Loss: 0.27880748824390306\n",
            "2020-12-06 15:14:05,267 INFO Training Accuracy: 90.39399999999999%\n",
            "2020-12-06 15:14:29,865 INFO Testing Loss: 0.6101366451382637\n",
            "2020-12-06 15:14:29,866 INFO Testing Accuracy: 80.60000000000001%\n",
            "2020-12-06 15:14:29,867 INFO Time: 284.27264881134033s\n",
            "2020-12-06 15:14:29,868 INFO ====================\n",
            "2020-12-06 15:14:30,337 INFO Seed: 2\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-12-06 15:14:32,252 INFO Epoch: 0\n",
            "2020-12-06 15:18:51,581 INFO Training Loss: 1.9603939833848372\n",
            "2020-12-06 15:18:51,583 INFO Training Accuracy: 27.107999999999997%\n",
            "2020-12-06 15:19:16,187 INFO Testing Loss: 1.8195032858848572\n",
            "2020-12-06 15:19:16,189 INFO Testing Accuracy: 31.900000000000002%\n",
            "2020-12-06 15:19:16,190 INFO Time: 283.9382474422455s\n",
            "2020-12-06 15:19:16,192 INFO ====================\n",
            "2020-12-06 15:19:16,193 INFO Epoch: 1\n",
            "2020-12-06 15:23:33,780 INFO Training Loss: 1.6921703169108047\n",
            "2020-12-06 15:23:33,781 INFO Training Accuracy: 37.702000000000005%\n",
            "2020-12-06 15:23:58,099 INFO Testing Loss: 1.5884682512283326\n",
            "2020-12-06 15:23:58,101 INFO Testing Accuracy: 40.01%\n",
            "2020-12-06 15:23:58,102 INFO Time: 281.90831303596497s\n",
            "2020-12-06 15:23:58,104 INFO ====================\n",
            "2020-12-06 15:23:58,105 INFO Epoch: 2\n",
            "2020-12-06 15:28:14,960 INFO Training Loss: 1.5596873138261877\n",
            "2020-12-06 15:28:14,962 INFO Training Accuracy: 42.622%\n",
            "2020-12-06 15:28:39,743 INFO Testing Loss: 1.5153713369369506\n",
            "2020-12-06 15:28:39,744 INFO Testing Accuracy: 43.419999999999995%\n",
            "2020-12-06 15:28:39,745 INFO Time: 281.6401319503784s\n",
            "2020-12-06 15:28:39,747 INFO ====================\n",
            "2020-12-06 15:28:39,748 INFO Epoch: 3\n",
            "2020-12-06 15:32:58,068 INFO Training Loss: 1.4611080924568274\n",
            "2020-12-06 15:32:58,070 INFO Training Accuracy: 46.514%\n",
            "2020-12-06 15:33:22,641 INFO Testing Loss: 1.3833413624763489\n",
            "2020-12-06 15:33:22,643 INFO Testing Accuracy: 50.38%\n",
            "2020-12-06 15:33:22,644 INFO Time: 282.8961308002472s\n",
            "2020-12-06 15:33:22,645 INFO ====================\n",
            "2020-12-06 15:33:22,647 INFO Epoch: 4\n",
            "2020-12-06 15:37:43,351 INFO Training Loss: 1.367647305169069\n",
            "2020-12-06 15:37:43,352 INFO Training Accuracy: 50.324000000000005%\n",
            "2020-12-06 15:38:08,211 INFO Testing Loss: 1.3456325614452362\n",
            "2020-12-06 15:38:08,213 INFO Testing Accuracy: 51.85999999999999%\n",
            "2020-12-06 15:38:08,214 INFO Time: 285.5677375793457s\n",
            "2020-12-06 15:38:08,216 INFO ====================\n",
            "2020-12-06 15:38:08,217 INFO Epoch: 5\n",
            "2020-12-06 15:42:29,660 INFO Training Loss: 1.2855835683510433\n",
            "2020-12-06 15:42:29,662 INFO Training Accuracy: 53.891999999999996%\n",
            "2020-12-06 15:42:54,668 INFO Testing Loss: 1.2407774531841278\n",
            "2020-12-06 15:42:54,669 INFO Testing Accuracy: 54.96%\n",
            "2020-12-06 15:42:54,671 INFO Time: 286.45412254333496s\n",
            "2020-12-06 15:42:54,673 INFO ====================\n",
            "2020-12-06 15:42:54,675 INFO Epoch: 6\n",
            "2020-12-06 15:47:18,726 INFO Training Loss: 1.2053453711902393\n",
            "2020-12-06 15:47:18,728 INFO Training Accuracy: 56.814%\n",
            "2020-12-06 15:47:43,856 INFO Testing Loss: 1.1637475645542146\n",
            "2020-12-06 15:47:43,857 INFO Testing Accuracy: 57.95%\n",
            "2020-12-06 15:47:43,858 INFO Time: 289.1838068962097s\n",
            "2020-12-06 15:47:43,859 INFO ====================\n",
            "2020-12-06 15:47:43,861 INFO Epoch: 7\n",
            "2020-12-06 15:52:11,774 INFO Training Loss: 1.126663935306432\n",
            "2020-12-06 15:52:11,776 INFO Training Accuracy: 59.882000000000005%\n",
            "2020-12-06 15:52:36,895 INFO Testing Loss: 1.0846356230974197\n",
            "2020-12-06 15:52:36,897 INFO Testing Accuracy: 61.06%\n",
            "2020-12-06 15:52:36,898 INFO Time: 293.03712248802185s\n",
            "2020-12-06 15:52:36,899 INFO ====================\n",
            "2020-12-06 15:52:36,900 INFO Epoch: 8\n",
            "2020-12-06 15:56:58,267 INFO Training Loss: 1.0513887911501443\n",
            "2020-12-06 15:56:58,269 INFO Training Accuracy: 62.702000000000005%\n",
            "2020-12-06 15:57:23,079 INFO Testing Loss: 1.0050063675642014\n",
            "2020-12-06 15:57:23,081 INFO Testing Accuracy: 64.42%\n",
            "2020-12-06 15:57:23,082 INFO Time: 286.18157482147217s\n",
            "2020-12-06 15:57:23,084 INFO ====================\n",
            "2020-12-06 15:57:23,085 INFO Epoch: 9\n",
            "2020-12-06 16:01:43,771 INFO Training Loss: 0.9912995203681614\n",
            "2020-12-06 16:01:43,772 INFO Training Accuracy: 65.00399999999999%\n",
            "2020-12-06 16:02:08,538 INFO Testing Loss: 0.9542287045717239\n",
            "2020-12-06 16:02:08,539 INFO Testing Accuracy: 66.49000000000001%\n",
            "2020-12-06 16:02:08,542 INFO Time: 285.4576599597931s\n",
            "2020-12-06 16:02:08,543 INFO ====================\n",
            "2020-12-06 16:02:08,545 INFO Epoch: 10\n",
            "2020-12-06 16:06:25,471 INFO Training Loss: 0.9338498135356952\n",
            "2020-12-06 16:06:25,473 INFO Training Accuracy: 66.788%\n",
            "2020-12-06 16:06:49,738 INFO Testing Loss: 0.9387446445226669\n",
            "2020-12-06 16:06:49,740 INFO Testing Accuracy: 66.47999999999999%\n",
            "2020-12-06 16:06:49,741 INFO Time: 281.1959671974182s\n",
            "2020-12-06 16:06:49,742 INFO ====================\n",
            "2020-12-06 16:06:49,743 INFO Epoch: 11\n",
            "2020-12-06 16:11:05,055 INFO Training Loss: 0.880098301126524\n",
            "2020-12-06 16:11:05,057 INFO Training Accuracy: 68.85%\n",
            "2020-12-06 16:11:29,270 INFO Testing Loss: 0.9119221812486649\n",
            "2020-12-06 16:11:29,272 INFO Testing Accuracy: 68.39%\n",
            "2020-12-06 16:11:29,274 INFO Time: 279.5301561355591s\n",
            "2020-12-06 16:11:29,275 INFO ====================\n",
            "2020-12-06 16:11:29,276 INFO Epoch: 12\n",
            "2020-12-06 16:15:45,652 INFO Training Loss: 0.828218959786398\n",
            "2020-12-06 16:15:45,654 INFO Training Accuracy: 70.94%\n",
            "2020-12-06 16:16:10,070 INFO Testing Loss: 0.852904577255249\n",
            "2020-12-06 16:16:10,072 INFO Testing Accuracy: 69.78999999999999%\n",
            "2020-12-06 16:16:10,073 INFO Time: 280.79731583595276s\n",
            "2020-12-06 16:16:10,075 INFO ====================\n",
            "2020-12-06 16:16:10,076 INFO Epoch: 13\n",
            "2020-12-06 16:20:24,655 INFO Training Loss: 0.7716738128906016\n",
            "2020-12-06 16:20:24,659 INFO Training Accuracy: 72.762%\n",
            "2020-12-06 16:20:48,883 INFO Testing Loss: 0.7966035115718841\n",
            "2020-12-06 16:20:48,884 INFO Testing Accuracy: 72.25%\n",
            "2020-12-06 16:20:48,885 INFO Time: 278.8092179298401s\n",
            "2020-12-06 16:20:48,887 INFO ====================\n",
            "2020-12-06 16:20:48,888 INFO Epoch: 14\n",
            "2020-12-06 16:25:02,814 INFO Training Loss: 0.7274536418030634\n",
            "2020-12-06 16:25:02,815 INFO Training Accuracy: 74.196%\n",
            "2020-12-06 16:25:27,243 INFO Testing Loss: 0.7739099287986755\n",
            "2020-12-06 16:25:27,245 INFO Testing Accuracy: 73.63%\n",
            "2020-12-06 16:25:27,247 INFO Time: 278.35879731178284s\n",
            "2020-12-06 16:25:27,249 INFO ====================\n",
            "2020-12-06 16:25:27,249 INFO Epoch: 15\n",
            "2020-12-06 16:29:41,515 INFO Training Loss: 0.684334922324666\n",
            "2020-12-06 16:29:41,517 INFO Training Accuracy: 76.056%\n",
            "2020-12-06 16:30:05,685 INFO Testing Loss: 0.7423637318611145\n",
            "2020-12-06 16:30:05,687 INFO Testing Accuracy: 74.48%\n",
            "2020-12-06 16:30:05,688 INFO Time: 278.43839478492737s\n",
            "2020-12-06 16:30:05,689 INFO ====================\n",
            "2020-12-06 16:30:05,690 INFO Epoch: 16\n",
            "2020-12-06 16:34:21,040 INFO Training Loss: 0.6389066246921754\n",
            "2020-12-06 16:34:21,042 INFO Training Accuracy: 77.476%\n",
            "2020-12-06 16:34:45,215 INFO Testing Loss: 0.7256161996722221\n",
            "2020-12-06 16:34:45,216 INFO Testing Accuracy: 75.2%\n",
            "2020-12-06 16:34:45,217 INFO Time: 279.5275299549103s\n",
            "2020-12-06 16:34:45,219 INFO ====================\n",
            "2020-12-06 16:34:45,220 INFO Epoch: 17\n",
            "2020-12-06 16:38:58,964 INFO Training Loss: 0.5971158615615971\n",
            "2020-12-06 16:38:58,966 INFO Training Accuracy: 78.996%\n",
            "2020-12-06 16:39:23,362 INFO Testing Loss: 0.74192650526762\n",
            "2020-12-06 16:39:23,364 INFO Testing Accuracy: 74.86%\n",
            "2020-12-06 16:39:23,367 INFO Time: 278.1468541622162s\n",
            "2020-12-06 16:39:23,368 INFO ====================\n",
            "2020-12-06 16:39:23,369 INFO Epoch: 18\n",
            "2020-12-06 16:43:37,121 INFO Training Loss: 0.5593479653758466\n",
            "2020-12-06 16:43:37,123 INFO Training Accuracy: 80.33200000000001%\n",
            "2020-12-06 16:44:01,321 INFO Testing Loss: 0.7065925228595734\n",
            "2020-12-06 16:44:01,322 INFO Testing Accuracy: 76.17%\n",
            "2020-12-06 16:44:01,323 INFO Time: 277.954372882843s\n",
            "2020-12-06 16:44:01,325 INFO ====================\n",
            "2020-12-06 16:44:01,327 INFO Epoch: 19\n",
            "2020-12-06 16:48:14,908 INFO Training Loss: 0.5231695826096303\n",
            "2020-12-06 16:48:14,909 INFO Training Accuracy: 81.46%\n",
            "2020-12-06 16:48:39,166 INFO Testing Loss: 0.6809815716743469\n",
            "2020-12-06 16:48:39,170 INFO Testing Accuracy: 77.60000000000001%\n",
            "2020-12-06 16:48:39,174 INFO Time: 277.84698843955994s\n",
            "2020-12-06 16:48:39,176 INFO ====================\n",
            "2020-12-06 16:48:39,177 INFO Epoch: 20\n",
            "2020-12-06 16:52:56,628 INFO Training Loss: 0.4939896728833923\n",
            "2020-12-06 16:52:56,630 INFO Training Accuracy: 82.464%\n",
            "2020-12-06 16:53:20,785 INFO Testing Loss: 0.6569577986001969\n",
            "2020-12-06 16:53:20,786 INFO Testing Accuracy: 78.34%\n",
            "2020-12-06 16:53:20,788 INFO Time: 281.61081051826477s\n",
            "2020-12-06 16:53:20,789 INFO ====================\n",
            "2020-12-06 16:53:20,790 INFO Epoch: 21\n",
            "2020-12-06 16:57:32,969 INFO Training Loss: 0.46714067024648037\n",
            "2020-12-06 16:57:32,971 INFO Training Accuracy: 83.54%\n",
            "2020-12-06 16:57:57,157 INFO Testing Loss: 0.6453327029943466\n",
            "2020-12-06 16:57:57,159 INFO Testing Accuracy: 78.47%\n",
            "2020-12-06 16:57:57,160 INFO Time: 276.3697998523712s\n",
            "2020-12-06 16:57:57,161 INFO ====================\n",
            "2020-12-06 16:57:57,162 INFO Epoch: 22\n",
            "2020-12-06 17:02:10,329 INFO Training Loss: 0.4301716977220667\n",
            "2020-12-06 17:02:10,330 INFO Training Accuracy: 84.78%\n",
            "2020-12-06 17:02:34,286 INFO Testing Loss: 0.6929113897681236\n",
            "2020-12-06 17:02:34,287 INFO Testing Accuracy: 77.82%\n",
            "2020-12-06 17:02:34,288 INFO Time: 277.1259195804596s\n",
            "2020-12-06 17:02:34,289 INFO ====================\n",
            "2020-12-06 17:02:34,291 INFO Epoch: 23\n",
            "2020-12-06 17:06:47,920 INFO Training Loss: 0.40780065271555616\n",
            "2020-12-06 17:06:47,922 INFO Training Accuracy: 85.676%\n",
            "2020-12-06 17:07:12,518 INFO Testing Loss: 0.6209251925349235\n",
            "2020-12-06 17:07:12,519 INFO Testing Accuracy: 79.25999999999999%\n",
            "2020-12-06 17:07:12,521 INFO Time: 278.2301049232483s\n",
            "2020-12-06 17:07:12,522 INFO ====================\n",
            "2020-12-06 17:07:12,523 INFO Epoch: 24\n",
            "2020-12-06 17:11:26,213 INFO Training Loss: 0.3775891446701401\n",
            "2020-12-06 17:11:26,215 INFO Training Accuracy: 86.504%\n",
            "2020-12-06 17:11:49,996 INFO Testing Loss: 0.6517851945757865\n",
            "2020-12-06 17:11:49,997 INFO Testing Accuracy: 79.11%\n",
            "2020-12-06 17:11:49,999 INFO Time: 277.4760015010834s\n",
            "2020-12-06 17:11:50,001 INFO ====================\n",
            "2020-12-06 17:11:50,002 INFO Epoch: 25\n",
            "2020-12-06 17:15:59,137 INFO Training Loss: 0.36039971466869347\n",
            "2020-12-06 17:15:59,138 INFO Training Accuracy: 87.264%\n",
            "2020-12-06 17:16:23,056 INFO Testing Loss: 0.633962190747261\n",
            "2020-12-06 17:16:23,057 INFO Testing Accuracy: 79.66%\n",
            "2020-12-06 17:16:23,059 INFO Time: 273.0567579269409s\n",
            "2020-12-06 17:16:23,060 INFO ====================\n",
            "2020-12-06 17:16:23,062 INFO Epoch: 26\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch    26: reducing learning rate of group 0 to 1.0000e-05.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-12-06 17:20:32,571 INFO Training Loss: 0.2611273646240344\n",
            "2020-12-06 17:20:32,572 INFO Training Accuracy: 91.096%\n",
            "2020-12-06 17:20:56,319 INFO Testing Loss: 0.5651213747262954\n",
            "2020-12-06 17:20:56,321 INFO Testing Accuracy: 81.73%\n",
            "2020-12-06 17:20:56,322 INFO Time: 273.25961446762085s\n",
            "2020-12-06 17:20:56,322 INFO ====================\n",
            "2020-12-06 17:20:56,323 INFO Epoch: 27\n",
            "2020-12-06 17:25:05,291 INFO Training Loss: 0.2337536294861218\n",
            "2020-12-06 17:25:05,293 INFO Training Accuracy: 92.238%\n",
            "2020-12-06 17:25:28,904 INFO Testing Loss: 0.5656902304291725\n",
            "2020-12-06 17:25:28,906 INFO Testing Accuracy: 82.16%\n",
            "2020-12-06 17:25:28,908 INFO Time: 272.58446764945984s\n",
            "2020-12-06 17:25:28,909 INFO ====================\n",
            "2020-12-06 17:25:28,911 INFO Epoch: 28\n",
            "2020-12-06 17:29:38,311 INFO Training Loss: 0.22340632477760924\n",
            "2020-12-06 17:29:38,313 INFO Training Accuracy: 92.522%\n",
            "2020-12-06 17:30:01,767 INFO Testing Loss: 0.5686032471060752\n",
            "2020-12-06 17:30:01,769 INFO Testing Accuracy: 82.07%\n",
            "2020-12-06 17:30:01,770 INFO Time: 272.85942816734314s\n",
            "2020-12-06 17:30:01,771 INFO ====================\n",
            "2020-12-06 17:30:01,773 INFO Epoch: 29\n",
            "2020-12-06 17:34:11,316 INFO Training Loss: 0.20855235453228207\n",
            "2020-12-06 17:34:11,318 INFO Training Accuracy: 92.93%\n",
            "2020-12-06 17:34:36,265 INFO Testing Loss: 0.5745591524243355\n",
            "2020-12-06 17:34:36,266 INFO Testing Accuracy: 82.13000000000001%\n",
            "2020-12-06 17:34:36,267 INFO Time: 274.4945442676544s\n",
            "2020-12-06 17:34:36,269 INFO ====================\n",
            "2020-12-06 17:34:36,270 INFO Epoch: 30\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-1b654e547251>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-205ebaead4f5>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, train_loader, criterion, optimizer)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                    )\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSNv7nAjiL4K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}