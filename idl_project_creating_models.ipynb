{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "idl_project_creating_models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Environment (conda_pytorch_latest_p37)",
      "language": "python",
      "name": "conda_pytorch_latest_p37"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaichengDING/Triple-Defense/blob/main/idl_project_creating_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcnIH59Pvv4n",
        "outputId": "306e9d2d-ca94-4689-a5fa-93ca453b8ccf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/ubuntu/project\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SqUPdAKkDIn",
        "outputId": "78fa7e18-e0d1-4fcc-ce5a-0fe92cce0d07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import PIL\n",
        "\n",
        "import sys\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "\n",
        "from torch.utils import data\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import logging\n",
        "import datetime\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "cuda"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52iA4Fj58APR",
        "outputId": "43dbf664-e6c8-4c72-929e-d3ff7e2135e9"
      },
      "source": [
        "! nvidia-smi\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Nov  4 20:52:27 2020       \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\r\n",
            "|-------------------------------+----------------------+----------------------+\r\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
            "|                               |                      |               MIG M. |\r\n",
            "|===============================+======================+======================|\r\n",
            "|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |\r\n",
            "| N/A   47C    P0    28W /  70W |      3MiB / 15109MiB |      0%      Default |\r\n",
            "|                               |                      |                  N/A |\r\n",
            "+-------------------------------+----------------------+----------------------+\r\n",
            "                                                                               \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| Processes:                                                                  |\r\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
            "|        ID   ID                                                   Usage      |\r\n",
            "|=============================================================================|\r\n",
            "|  No running processes found                                                 |\r\n",
            "+-----------------------------------------------------------------------------+\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfyaOczXoRqQ"
      },
      "source": [
        "class AddGaussianNoise(object):\n",
        "    def __init__(self, mean=0., std=1.):\n",
        "        self.std = std\n",
        "        self.mean = mean\n",
        "        \n",
        "    def __call__(self, tensor):\n",
        "      res = tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "      return torch.clamp(input=res, min=0.0, max=1.0)\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkIqO0-ntgcy"
      },
      "source": [
        "def train_epoch(model, train_loader, criterion, optimizer):\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    total_predictions = 0.0\n",
        "    correct_predictions = 0.0\n",
        "    \n",
        "    for batch_idx, (data, target) in enumerate(train_loader):   \n",
        "        optimizer.zero_grad()   # .backward() accumulates gradients\n",
        "        data = data.to(device)\n",
        "        target = target.to(device) # all data & model on same device\n",
        "        \n",
        "        with torch.cuda.amp.autocast():\n",
        "          outputs = model(data)\n",
        "          loss = criterion(outputs, target)\n",
        "          running_loss += loss.item()\n",
        "\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total_predictions += target.size(0)\n",
        "          correct_predictions += (predicted == target).sum().item()\n",
        "        \n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "\n",
        "        del data\n",
        "        del target\n",
        "    \n",
        "    \n",
        "    running_loss /= len(train_loader)\n",
        "    acc = (correct_predictions/total_predictions)*100.0\n",
        "    logging.info('Training Loss: {}'.format(running_loss))\n",
        "    logging.info('Training Accuracy: {}%'.format(acc))\n",
        "    return running_loss\n",
        "\n",
        "\n",
        "def test_model(model, test_loader, criterion):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "\n",
        "        running_loss = 0.0\n",
        "        total_predictions = 0.0\n",
        "        correct_predictions = 0.0\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(test_loader): \n",
        "            data = data.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "              outputs = model(data)\n",
        "\n",
        "              _, predicted = torch.max(outputs.data, 1)\n",
        "              total_predictions += target.size(0)\n",
        "              correct_predictions += (predicted == target).sum().item()\n",
        "\n",
        "              loss = criterion(outputs, target).detach()\n",
        "              running_loss += loss.item()\n",
        "\n",
        "            del data\n",
        "            del target\n",
        "\n",
        "        running_loss /= len(test_loader)\n",
        "        acc = (correct_predictions/total_predictions)*100.0\n",
        "        logging.info('Testing Loss: {}'.format(running_loss))\n",
        "        logging.info('Testing Accuracy: {}%'.format(acc))\n",
        "        return running_loss, acc\n",
        "\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Conv2d or type(m) == nn.Linear:\n",
        "        torch.nn.init.xavier_normal_(m.weight.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXX4443Y16Ul"
      },
      "source": [
        "# configure logging\n",
        "logger = logging.getLogger(\"\")\n",
        "\n",
        "# reset handler\n",
        "for handler in logging.root.handlers[:]:\n",
        "  logging.root.removeHandler(handler)\n",
        "\n",
        "# set handler\n",
        "stream_hdlr = logging.StreamHandler()\n",
        "file_hdlr = logging.FileHandler('/home/ubuntu/project/log_{}.log'.format(datetime.datetime.now()))\n",
        "\n",
        "formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
        "stream_hdlr.setFormatter(formatter)\n",
        "file_hdlr.setFormatter(formatter)\n",
        "\n",
        "logger.addHandler(stream_hdlr)\n",
        "logger.addHandler(file_hdlr)\n",
        "\n",
        "logger.setLevel(logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq_mk_bEBtlt"
      },
      "source": [
        "class VGG16(nn.Module):\n",
        "    def __init__(self, nb_classes=10):\n",
        "        super(VGG16, self).__init__()\n",
        "        self.vgg16 = models.vgg16_bn()\n",
        "        self.linear = nn.Linear(1000, nb_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.vgg16(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFZ8ZtrqxZ7j"
      },
      "source": [
        "train_batchsize = 128\n",
        "test_batchsize = 100\n",
        "num_workers = 8\n",
        "num_classes = 10\n",
        "\n",
        "n_epochs = 25\n",
        "img_size = 224\n",
        "lr = 1e-4\n",
        "min_lr = 1e-8\n",
        "weight_decay = 5e-4\n",
        "num_models = 30\n",
        "noise_std = 0.1\n",
        "\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "\n",
        "hyper_params = {'lr': lr, 'min_lr': min_lr, 'weight_decay': weight_decay, 'num_models': num_models, 'num_epochs': n_epochs, 'noise_std': noise_std}\n",
        "logging.info(hyper_params)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUfvg4LvwMA0"
      },
      "source": [
        "seeds = np.arange(0, num_models)\n",
        "\n",
        "for seed in seeds:\n",
        "  logging.info('Seed: {}'.format(seed))\n",
        "  torch.manual_seed(seed)\n",
        "  \n",
        "\n",
        "  train_transform = transforms.Compose([transforms.Resize(size=img_size),\n",
        "                      transforms.ColorJitter(hue=.05, saturation=.05),\n",
        "                      transforms.RandomHorizontalFlip(p=0.5),\n",
        "                      transforms.RandomRotation(20, resample=PIL.Image.BILINEAR),\n",
        "                      transforms.ToTensor(),\n",
        "                      transforms.Normalize((0, 0, 0), (1, 1, 1)),\n",
        "                      AddGaussianNoise(0., noise_std)])\n",
        "\n",
        "  test_transform = transforms.Compose([transforms.Resize(size=img_size),\n",
        "                     transforms.ToTensor(),\n",
        "                     transforms.Normalize((0, 0, 0), (1, 1, 1)),\n",
        "                     AddGaussianNoise(0., noise_std)])\n",
        "\n",
        "  \n",
        "  trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)\n",
        "  testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
        "  trainloader = torch.utils.data.DataLoader(trainset, batch_size=train_batchsize, shuffle=True, num_workers=num_workers)\n",
        "  testloader = torch.utils.data.DataLoader(testset, batch_size=test_batchsize, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "  model = VGG16(num_classes)\n",
        "  model.apply(init_weights)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "  scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=1, cooldown=5, min_lr=min_lr, verbose=True)\n",
        "  scaler = torch.cuda.amp.GradScaler()\n",
        "  model.to(device)\n",
        "\n",
        "  # Train_loss = []\n",
        "  # Test_loss = []\n",
        "  # Test_acc = []\n",
        "\n",
        "  for i in range(n_epochs):\n",
        "    tic = time.time()\n",
        "    logging.info('Epoch: {}'.format(i))\n",
        "    train_loss = train_epoch(model, trainloader, criterion, optimizer)\n",
        "    test_loss, test_acc = test_model(model, testloader, criterion)\n",
        "    scheduler.step(test_loss)\n",
        "    # Train_loss.append(train_loss)\n",
        "    # Test_loss.append(test_loss)\n",
        "    # Test_acc.append(test_acc)\n",
        "    toc = time.time()\n",
        "    logging.info('Time: {}s'.format(toc - tic))\n",
        "    logging.info('='*20)\n",
        "    \n",
        "  torch.save({'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'scheduler_state_dict': scheduler.state_dict()}, \n",
        "        \"/home/ubuntu/project/Model_{}\".format(datetime.datetime.now()))\n",
        "  \n",
        "  torch.cuda.empty_cache()\n",
        "  del model\n",
        "  del criterion\n",
        "  del optimizer\n",
        "  del scheduler\n",
        "  del scaler\n",
        "  del trainloader\n",
        "  del testloader\n",
        "  del train_transform\n",
        "  del test_transform\n",
        "\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}