{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8192\r\n"
     ]
    }
   ],
   "source": [
    "!ulimit -n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: adversarial-robustness-toolbox in /home/ubuntu/anaconda3/lib/python3.7/site-packages (1.4.2)\n",
      "Requirement already satisfied: statsmodels in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from adversarial-robustness-toolbox) (0.11.0)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from adversarial-robustness-toolbox) (4.42.1)\n",
      "Requirement already satisfied: setuptools in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from adversarial-robustness-toolbox) (45.2.0.post20200210)\n",
      "Requirement already satisfied: Pillow in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from adversarial-robustness-toolbox) (7.0.0)\n",
      "Requirement already satisfied: scikit-learn==0.22.2 in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from adversarial-robustness-toolbox) (0.22.2)\n",
      "Requirement already satisfied: six in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from adversarial-robustness-toolbox) (1.14.0)\n",
      "Requirement already satisfied: mypy in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from adversarial-robustness-toolbox) (0.790)\n",
      "Requirement already satisfied: pydub in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from adversarial-robustness-toolbox) (0.24.1)\n",
      "Requirement already satisfied: matplotlib in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from adversarial-robustness-toolbox) (3.1.3)\n",
      "Requirement already satisfied: ffmpeg-python in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from adversarial-robustness-toolbox) (0.2.0)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from adversarial-robustness-toolbox) (1.18.1)\n",
      "Requirement already satisfied: scipy==1.4.1 in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from adversarial-robustness-toolbox) (1.4.1)\n",
      "Requirement already satisfied: resampy in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from adversarial-robustness-toolbox) (0.2.2)\n",
      "Requirement already satisfied: cma in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from adversarial-robustness-toolbox) (3.0.3)\n",
      "Requirement already satisfied: pandas>=0.21 in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from statsmodels->adversarial-robustness-toolbox) (1.0.1)\n",
      "Requirement already satisfied: patsy>=0.5 in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from statsmodels->adversarial-robustness-toolbox) (0.5.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from scikit-learn==0.22.2->adversarial-robustness-toolbox) (0.14.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from mypy->adversarial-robustness-toolbox) (3.7.4.3)\n",
      "Requirement already satisfied: typed-ast<1.5.0,>=1.4.0 in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from mypy->adversarial-robustness-toolbox) (1.4.1)\n",
      "Requirement already satisfied: mypy-extensions<0.5.0,>=0.4.3 in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from mypy->adversarial-robustness-toolbox) (0.4.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from matplotlib->adversarial-robustness-toolbox) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from matplotlib->adversarial-robustness-toolbox) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from matplotlib->adversarial-robustness-toolbox) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from matplotlib->adversarial-robustness-toolbox) (2.4.6)\n",
      "Requirement already satisfied: future in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from ffmpeg-python->adversarial-robustness-toolbox) (0.18.2)\n",
      "Requirement already satisfied: numba>=0.32 in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from resampy->adversarial-robustness-toolbox) (0.48.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from pandas>=0.21->statsmodels->adversarial-robustness-toolbox) (2019.3)\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /home/ubuntu/anaconda3/lib/python3.7/site-packages (from numba>=0.32->resampy->adversarial-robustness-toolbox) (0.31.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install adversarial-robustness-toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4023,
     "status": "ok",
     "timestamp": 1604455457391,
     "user": {
      "displayName": "Kaicheng Ding",
      "photoUrl": "",
      "userId": "10577885083990106787"
     },
     "user_tz": 300
    },
    "id": "6SqUPdAKkDIn",
    "outputId": "48f9dbc6-90f2-4b28-f838-784ee00e4784"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import PIL\n",
    "\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "from torch.utils import data\n",
    "\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.attacks.evasion import ProjectedGradientDescentPyTorch\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import logging\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 489,
     "status": "ok",
     "timestamp": 1604455458596,
     "user": {
      "displayName": "Kaicheng Ding",
      "photoUrl": "",
      "userId": "10577885083990106787"
     },
     "user_tz": 300
    },
    "id": "PfyaOczXoRqQ"
   },
   "outputs": [],
   "source": [
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "      res = tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "      return torch.clamp(input=res, min=-0.5, max=0.5)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 290,
     "status": "ok",
     "timestamp": 1604455461127,
     "user": {
      "displayName": "Kaicheng Ding",
      "photoUrl": "",
      "userId": "10577885083990106787"
     },
     "user_tz": 300
    },
    "id": "zq_mk_bEBtlt"
   },
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self, nb_classes=10):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.vgg16 = models.vgg16_bn()\n",
    "        self.linear = nn.Linear(1000, nb_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.vgg16(x)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1604455464185,
     "user": {
      "displayName": "Kaicheng Ding",
      "photoUrl": "",
      "userId": "10577885083990106787"
     },
     "user_tz": 300
    },
    "id": "NkIqO0-ntgcy"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    total_predictions = 0.0\n",
    "    correct_predictions = 0.0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):   \n",
    "        optimizer.zero_grad()   # .backward() accumulates gradients\n",
    "        data = data.to(device)\n",
    "        target = target.to(device) # all data & model on same device\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "          outputs = model(data)\n",
    "          loss = criterion(outputs, target)\n",
    "          running_loss += loss.item()\n",
    "\n",
    "          _, predicted = torch.max(outputs.data, 1)\n",
    "          total_predictions += target.size(0)\n",
    "          correct_predictions += (predicted == target).sum().item()\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "\n",
    "        del data\n",
    "        del target\n",
    "    \n",
    "    \n",
    "    running_loss /= len(train_loader)\n",
    "    acc = (correct_predictions/total_predictions)*100.0\n",
    "    logging.info('Training Loss: {}'.format(running_loss))\n",
    "    logging.info('Training Accuracy: {}%'.format(acc))\n",
    "    return running_loss\n",
    "\n",
    "\n",
    "def test_model(model, test_loader, criterion):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        total_predictions = 0.0\n",
    "        correct_predictions = 0.0\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):   \n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            outputs = model(data)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_predictions += target.size(0)\n",
    "            correct_predictions += (predicted == target).sum().item()\n",
    "\n",
    "            loss = criterion(outputs, target).detach()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # with torch.cuda.amp.autocast():\n",
    "            #   outputs = model(data)\n",
    "\n",
    "            #   _, predicted = torch.max(outputs.data, 1)\n",
    "            #   total_predictions += target.size(0)\n",
    "            #   correct_predictions += (predicted == target).sum().item()\n",
    "\n",
    "            #   loss = criterion(outputs, target).detach()\n",
    "            #   running_loss += loss.item()\n",
    "            \n",
    "\n",
    "            del data\n",
    "            del target\n",
    "\n",
    "        running_loss /= len(test_loader)\n",
    "        acc = (correct_predictions/total_predictions)*100.0\n",
    "        logging.info('Testing Loss: {}'.format(running_loss))\n",
    "        logging.info('Testing Accuracy: {}%'.format(acc))\n",
    "        return running_loss, acc\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Conv2d or type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_normal_(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 275,
     "status": "ok",
     "timestamp": 1604455474293,
     "user": {
      "displayName": "Kaicheng Ding",
      "photoUrl": "",
      "userId": "10577885083990106787"
     },
     "user_tz": 300
    },
    "id": "dXX4443Y16Ul"
   },
   "outputs": [],
   "source": [
    "# configure logging\n",
    "logger = logging.getLogger(\"\")\n",
    "\n",
    "# reset handler\n",
    "for handler in logging.root.handlers[:]:\n",
    "  logging.root.removeHandler(handler)\n",
    "\n",
    "# set handler\n",
    "stream_hdlr = logging.StreamHandler()\n",
    "file_hdlr = logging.FileHandler('/home/ubuntu/project/logs/'.format(datetime.datetime.now()))\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
    "stream_hdlr.setFormatter(formatter)\n",
    "file_hdlr.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(stream_hdlr)\n",
    "logger.addHandler(file_hdlr)\n",
    "\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 281,
     "status": "ok",
     "timestamp": 1604455476308,
     "user": {
      "displayName": "Kaicheng Ding",
      "photoUrl": "",
      "userId": "10577885083990106787"
     },
     "user_tz": 300
    },
    "id": "fFZ8ZtrqxZ7j",
    "outputId": "3859a66d-e1d2-41d5-9254-1b4bc7ca55e6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-07 04:07:00,968 INFO {'lr': 0.0001, 'min_lr': 1e-08, 'weight_decay': 0.0005, 'num_models': 10, 'num_epochs': 30, 'noise_std': 0.06}\n"
     ]
    }
   ],
   "source": [
    "train_batchsize = 128\n",
    "test_batchsize = 100\n",
    "num_workers = 4\n",
    "num_classes = 10\n",
    "\n",
    "n_epochs = 30\n",
    "img_size = 224\n",
    "lr = 1e-4\n",
    "min_lr = 1e-8\n",
    "weight_decay = 5e-4\n",
    "num_models = 10\n",
    "noise_std = 0.06\n",
    "\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "hyper_params = {'lr': lr, 'min_lr': min_lr, 'weight_decay': weight_decay, 'num_models': num_models, 'num_epochs': n_epochs, 'noise_std': noise_std}\n",
    "logging.info(hyper_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XptTRte_fTyZ"
   },
   "source": [
    "# Ensemble Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEnsemble(nn.Module):\n",
    "    def __init__(self, model_list, num_models_selected, num_classes=10):\n",
    "        super(MyEnsemble, self).__init__()\n",
    "        self.model_list = []\n",
    "        self.num_models = len(model_list)\n",
    "        self.num_models_selected = num_models_selected\n",
    "        self.num_classes = num_classes\n",
    "        for model in model_list:\n",
    "          self.model_list.append(model)\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        # generate random indices\n",
    "        indices = [i for i in range(self.num_models)]\n",
    "        random.shuffle(indices)\n",
    "        indices = indices[:self.num_models_selected]\n",
    "        models_selected = [self.model_list[idx] for idx in indices]\n",
    "\n",
    "        noise = torch.randn(x.size()) * noise_std\n",
    "        noise = noise.to(device)\n",
    "        x_noised = x + noise\n",
    "\n",
    "        loss_sum = torch.Tensor(0.0)\n",
    "        \n",
    "        for model in models_selected:\n",
    "            model = model.to(device)\n",
    "            logits = model(x_noised)\n",
    "            loss = criterion(logits, y)\n",
    "            loss_sum += loss\n",
    "            model = model.to('cpu')\n",
    "        \n",
    "        return loss_sum\n",
    "    \n",
    "    def predict(self, x):\n",
    "        raise NotImplemented(\"predict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPytorchClassifier(PyTorchClassifier):\n",
    "    def loss_gradient(self, x: np.ndarray, y: np.ndarray, **kwargs) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute the gradient of the loss function w.r.t. `x`.\n",
    "        :param x: Sample input with shape as expected by the model.\n",
    "        :param y: Target values (class labels) one-hot-encoded of shape `(nb_samples, nb_classes)` or indices of shape\n",
    "                  `(nb_samples,)`.\n",
    "        :return: Array of gradients of the same shape as `x`.\n",
    "        \"\"\"\n",
    "        import torch  # lgtm [py/repeated-import]\n",
    "\n",
    "        # Apply preprocessing\n",
    "        x_preprocessed, y_preprocessed = self._apply_preprocessing(x, y, fit=False)\n",
    "\n",
    "        # Check label shape\n",
    "        y_preprocessed = self.reduce_labels(y_preprocessed)\n",
    "\n",
    "        # Convert the inputs to Tensors\n",
    "        inputs_t = torch.from_numpy(x_preprocessed).to(self._device)\n",
    "        inputs_t.requires_grad = True\n",
    "\n",
    "        # Convert the labels to Tensors\n",
    "        labels_t = torch.from_numpy(y_preprocessed).to(self._device)\n",
    "\n",
    "        # Compute the gradient and return\n",
    "        model_outputs = self._model(inputs_t, labels_t)\n",
    "\n",
    "        # Clean gradients\n",
    "        self._model.zero_grad()\n",
    "\n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "        grads = inputs_t.grad.cpu().numpy().copy()  # type: ignore\n",
    "        grads = self._apply_preprocessing_gradient(x, grads)\n",
    "        assert grads.shape == x.shape\n",
    "\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 263,
     "status": "ok",
     "timestamp": 1604457289367,
     "user": {
      "displayName": "Kaicheng Ding",
      "photoUrl": "",
      "userId": "10577885083990106787"
     },
     "user_tz": 300
    },
    "id": "8gmaPLUNc4ML"
   },
   "outputs": [],
   "source": [
    "# class MyEnsemble(nn.Module):\n",
    "#     def __init__(self, model_list, num_models, num_models_selected, num_classes=10):\n",
    "#         super(MyEnsemble, self).__init__()\n",
    "#         self.model_list = []\n",
    "#         self.num_models = num_models\n",
    "#         self.num_models_selected = num_models_selected\n",
    "#         self.num_classes = num_classes\n",
    "#         for model in model_list:\n",
    "#           self.model_list.append(model)\n",
    "#         # Remove last linear layer\n",
    "#         self.softmax = nn.Softmax()\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         # mask = torch.randperm(num_models)[:num_models_selected]\n",
    "#         !nvidia-smi\n",
    "#         indices = [i for i in range(self.num_models)]\n",
    "#         random.shuffle(indices)\n",
    "#         indices = indices[:self.num_models_selected]\n",
    "#         models_selected = [self.model_list[idx] for idx in indices]\n",
    "\n",
    "#         logits_list = []\n",
    "#         labels_list = []\n",
    "\n",
    "#         noise = torch.randn(x.size()) * noise_std\n",
    "#         noise = noise.to(device)\n",
    "#         x_noised = x + noise\n",
    "\n",
    "#         for model in models_selected:\n",
    "#           logits = model(x_noised)\n",
    "#           label_out = torch.unsqueeze(torch.argmax(self.softmax(logits), dim=1), dim=0)\n",
    "#           logits = torch.unsqueeze(logits, dim=0)\n",
    "#           labels_list.append(label_out)\n",
    "#           logits_list.append(logits)\n",
    "        \n",
    "#         # majority vote\n",
    "#         labels_tensor = torch.cat(labels_list, dim=0)\n",
    "#         logits_tensor = torch.cat(logits_list, dim=0)\n",
    "#         voted_class = torch.max(labels_tensor, dim=0) # possibly ties\n",
    "#         mask = (labels_tensor == voted_class.values).int()\n",
    "\n",
    "#         mask = mask.unsqueeze(dim=1).repeat(1, num_classes, 1)\n",
    "#         mask = mask.transpose(1, 2)\n",
    "\n",
    "#         sum_logits = torch.sum(mask * logits_tensor, dim=0)\n",
    "#         divider = torch.sum(mask, dim=0)\n",
    "        \n",
    "#         del logits_list\n",
    "#         del labels_list\n",
    "#         del labels_tensor\n",
    "#         del logits_tensor\n",
    "#         del voted_class\n",
    "#         del mask\n",
    "#         models_selected = []\n",
    "#         !nvidia-smi\n",
    "#         return sum_logits / divider\n",
    "\n",
    "#         # max_logits = torch.max(mask * logits_tensor, dim=0)\n",
    "#         # return max_logits.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MyEnsemble(nn.Module):\n",
    "#     def __init__(self, model_list, num_models, num_models_selected, num_classes=10):\n",
    "#         super(MyEnsemble, self).__init__()\n",
    "#         self.model_list = []\n",
    "#         self.num_models = num_models\n",
    "#         self.num_models_selected = num_models_selected\n",
    "#         self.num_classes = num_classes\n",
    "#         for model in model_list:\n",
    "#           self.model_list.append(model)\n",
    "#         # Remove last linear layer\n",
    "#         self.softmax = nn.Softmax()\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         indices = [i for i in range(self.num_models)]\n",
    "#         random.shuffle(indices)\n",
    "#         indices = indices[:self.num_models_selected]\n",
    "#         model_names_selected = [self.model_list[idx] for idx in indices]\n",
    "        \n",
    "#         models_selected = []\n",
    "        \n",
    "#         for model_name in model_names_selected:\n",
    "#           model = VGG16()\n",
    "#           model_data = torch.load('/home/ubuntu/project/{}'.format(model_name))\n",
    "#           model.load_state_dict(model_data['model_state_dict'])\n",
    "#           model.to(device)\n",
    "#           models_selected.append(model)\n",
    "\n",
    "#         logits_list = []\n",
    "#         labels_list = []\n",
    "\n",
    "#         noise = torch.randn(x.size()) * noise_std\n",
    "#         noise = noise.to(device)\n",
    "#         x_noised = x + noise\n",
    "\n",
    "#         for model in models_selected:\n",
    "#           logits = model(x_noised)\n",
    "#           label_out = torch.unsqueeze(torch.argmax(self.softmax(logits), dim=1), dim=0)\n",
    "#           logits = torch.unsqueeze(logits, dim=0)\n",
    "#           labels_list.append(label_out)\n",
    "#           logits_list.append(logits)\n",
    "        \n",
    "#         # majority vote\n",
    "#         labels_tensor = torch.cat(labels_list, dim=0)\n",
    "#         logits_tensor = torch.cat(logits_list, dim=0)\n",
    "#         voted_class = torch.max(labels_tensor, dim=0) # possibly ties\n",
    "#         mask = (labels_tensor == voted_class.values).int()\n",
    "\n",
    "#         mask = mask.unsqueeze(dim=1).repeat(1, num_classes, 1)\n",
    "#         mask = mask.transpose(1, 2)\n",
    "\n",
    "#         sum_logits = torch.sum(mask * logits_tensor, dim=0)\n",
    "#         divider = torch.sum(mask, dim=0)\n",
    "        \n",
    "#         for model in models_selected:\n",
    "#             del model\n",
    "#         del models_selected\n",
    "\n",
    "#         return sum_logits / divider\n",
    "\n",
    "#         # max_logits = torch.max(mask * logits_tensor, dim=0)\n",
    "#         # return max_logits.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCRrEOSBTTKs"
   },
   "source": [
    "# Ensemble Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['Model_30', \n",
    "               'Model_31',\n",
    "               'Model_32',\n",
    "               'Model_33',\n",
    "               'Model_34',\n",
    "               'Model_35',\n",
    "               'Model_90',\n",
    "               'Model_92',\n",
    "               'Model_93',\n",
    "               'Model_94',\n",
    "               'Model_a',\n",
    "               'Model_b',\n",
    "               'mod_k_1',\n",
    "               'mod_k_2',\n",
    "               'mod_k_3',\n",
    "               'mod_k_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 270,
     "status": "ok",
     "timestamp": 1604456978032,
     "user": {
      "displayName": "Kaicheng Ding",
      "photoUrl": "",
      "userId": "10577885083990106787"
     },
     "user_tz": 300
    },
    "id": "MUiLYb1EeNtS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "model_names = model_names[:5]\n",
    "num_models = len(model_names)\n",
    "num_models_selected = 3\n",
    "num_classes = 10\n",
    "print(num_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOPbwP7FTWEY"
   },
   "source": [
    "# Load Saved Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov  7 04:07:11 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   40C    P8     9W /  70W |      3MiB / 15109MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 85798,
     "status": "ok",
     "timestamp": 1604455597817,
     "user": {
      "displayName": "Kaicheng Ding",
      "photoUrl": "",
      "userId": "10577885083990106787"
     },
     "user_tz": 300
    },
    "id": "uTZ8lv9zdBzZ"
   },
   "outputs": [],
   "source": [
    "model_list = []\n",
    "for model_name in model_names:\n",
    "  model = VGG16()\n",
    "  model_data = torch.load('/home/ubuntu/project/{}'.format(model_name))\n",
    "  model.load_state_dict(model_data['model_state_dict'])\n",
    "  model_list.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov  7 04:29:47 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   50C    P0    27W /  70W |   3930MiB / 15109MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A     23222      C   ...rch_latest_p36/bin/python     3927MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GtXO3x71Ta-b"
   },
   "source": [
    "# Create Ensemble Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 278,
     "status": "ok",
     "timestamp": 1604457294669,
     "user": {
      "displayName": "Kaicheng Ding",
      "photoUrl": "",
      "userId": "10577885083990106787"
     },
     "user_tz": 300
    },
    "id": "mEUfjkIAc80L",
    "outputId": "1f990c80-60fd-4fec-f569-82f7d31a8652"
   },
   "outputs": [],
   "source": [
    "my_ensemble = MyEnsemble(model_list, num_models_selected, num_classes=10)\n",
    "# my_ensemble = MyEnsemble(model_names, num_models, num_models_selected, num_classes=10)\n",
    "#my_ensemble.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pdAezsETlff"
   },
   "source": [
    "# Create classifier object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 251,
     "status": "ok",
     "timestamp": 1604458860494,
     "user": {
      "displayName": "Kaicheng Ding",
      "photoUrl": "",
      "userId": "10577885083990106787"
     },
     "user_tz": 300
    },
    "id": "nKa7zNK71qHi",
    "outputId": "5cf41a29-3e9d-435c-8b3e-2d6a577dba52"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-07 04:29:51,695 INFO Inferred 1 hidden layers on PyTorch classifier.\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "classifier = MyPytorchClassifier(\n",
    "    model=my_ensemble,\n",
    "    clip_values=(0, 1),\n",
    "    loss=criterion,\n",
    "    input_shape=(3, 224, 224),\n",
    "    nb_classes=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7-E7mJaT5WR"
   },
   "source": [
    "# Create attack object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1604458867051,
     "user": {
      "displayName": "Kaicheng Ding",
      "photoUrl": "",
      "userId": "10577885083990106787"
     },
     "user_tz": 300
    },
    "id": "ov3ITMpM184G"
   },
   "outputs": [],
   "source": [
    "attack = FastGradientMethod(estimator=classifier, eps=0.01)\n",
    "# attack = ProjectedGradientDescentPyTorch(estimator=classifier, eps=0.1, eps_step=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BFiB-FbgT9sk"
   },
   "source": [
    "# Get test examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1105,
     "status": "ok",
     "timestamp": 1604459758651,
     "user": {
      "displayName": "Kaicheng Ding",
      "photoUrl": "",
      "userId": "10577885083990106787"
     },
     "user_tz": 300
    },
    "id": "XV2pPKKzeESx",
    "outputId": "9a6c0673-0473-4361-bf59-eaa4fb584c7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "test_transform = transforms.Compose([transforms.Resize(size=img_size),\n",
    "                     transforms.ToTensor(),\n",
    "                     transforms.Normalize((0, 0, 0), (1, 1, 1))])\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27103,
     "status": "ok",
     "timestamp": 1604460793290,
     "user": {
      "displayName": "Kaicheng Ding",
      "photoUrl": "",
      "userId": "10577885083990106787"
     },
     "user_tz": 300
    },
    "id": "kcNXJTnK2AnX",
    "outputId": "b3d13dcd-73d6-485c-940e-a968bd624993"
   },
   "outputs": [],
   "source": [
    "# x_test = []\n",
    "# y_test = []\n",
    "# for batch_idx, (X, Y) in enumerate(testloader):\n",
    "#   x_test.append(X.squeeze().numpy())\n",
    "#   y_test.append(Y[0].item())\n",
    "# x_test = np.array(x_test)\n",
    "# print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "x_test = []\n",
    "y_test = []\n",
    "for (x, y) in testset:\n",
    "    x_test.append(x.num)\n",
    "    y_test.append(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eToEAtOUUGzQ"
   },
   "source": [
    "# Generating attack samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov  5 22:56:47 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   50C    P0    27W /  70W |   6058MiB / 15109MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A     24047      C   ...rch_latest_p36/bin/python     6055MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 210285,
     "status": "ok",
     "timestamp": 1604459084583,
     "user": {
      "displayName": "Kaicheng Ding",
      "photoUrl": "",
      "userId": "10577885083990106787"
     },
     "user_tz": 300
    },
    "id": "ut3BYZJ62QSD",
    "outputId": "e9a8c521-a7fc-4a55-e36b-edf9683775af"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-05 22:56:55,000 INFO Using model predictions as correct labels for FGM.\n",
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/ipykernel/__main__.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 196.00 MiB (GPU 0; 14.76 GiB total capacity; 13.77 GiB already allocated; 97.75 MiB free; 13.90 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-f08c1ef1b7c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_test_adv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/art/attacks/attack.py\u001b[0m in \u001b[0;36mreplacement_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mreplacement_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/art/attacks/evasion/fast_gradient.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_random_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                     \u001b[0madv_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_project\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_random_init\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_random_init\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/art/attacks/evasion/fast_gradient.py\u001b[0m in \u001b[0;36m_compute\u001b[0;34m(self, x, x_init, y, mask, eps, eps_step, project, random_init)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;31m# Get perturbation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m             \u001b[0mperturbation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_perturbation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0;31m# Apply perturbation and clip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/art/attacks/evasion/fast_gradient.py\u001b[0m in \u001b[0;36m_compute_perturbation\u001b[0;34m(self, batch, batch_labels, mask)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;31m# Get gradient wrt loss; invert it if attack is targeted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargeted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;31m# Apply norm bound\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/art/estimators/classification/classifier.py\u001b[0m in \u001b[0;36mreplacement_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mreplacement_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/art/estimators/classification/pytorch.py\u001b[0m in \u001b[0;36mloss_gradient\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;31m# Compute the gradient and return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/art/estimators/classification/pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m                         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m                             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m                             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-2b219ea233cc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels_selected\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m           \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_noised\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m           \u001b[0mlabel_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m           \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-2eab35e1776a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torchvision/models/vgg.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             self.weight, self.bias, bn_training, exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2014\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   2015\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2016\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2017\u001b[0m     )\n\u001b[1;32m   2018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 196.00 MiB (GPU 0; 14.76 GiB total capacity; 13.77 GiB already allocated; 97.75 MiB free; 13.90 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "x_test_adv = attack.generate(x=x_test[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov  5 22:57:10 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   51C    P0    27W /  70W |  15012MiB / 15109MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A     24047      C   ...rch_latest_p36/bin/python    15009MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 359,
     "status": "ok",
     "timestamp": 1604456006569,
     "user": {
      "displayName": "Kaicheng Ding",
      "photoUrl": "",
      "userId": "10577885083990106787"
     },
     "user_tz": 300
    },
    "id": "Q7a-umqy73WF"
   },
   "outputs": [],
   "source": [
    "for i in range(len(y_test)):\n",
    "  y_test[i] = y_test[i].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1087,
     "status": "ok",
     "timestamp": 1604459164964,
     "user": {
      "displayName": "Kaicheng Ding",
      "photoUrl": "",
      "userId": "10577885083990106787"
     },
     "user_tz": 300
    },
    "id": "VXgK9rHW9Pr9",
    "outputId": "7f64ed9e-a361-4fb5-ea96-31753ca1809a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(x_test_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "executionInfo": {
     "elapsed": 279,
     "status": "ok",
     "timestamp": 1604459166124,
     "user": {
      "displayName": "Kaicheng Ding",
      "photoUrl": "",
      "userId": "10577885083990106787"
     },
     "user_tz": 300
    },
    "id": "0K5ii3_Z7B5d"
   },
   "outputs": [],
   "source": [
    "accuracy = np.sum(np.argmax(predictions, axis=1) == np.array(y_test)[:100]) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 231,
     "status": "ok",
     "timestamp": 1604459166937,
     "user": {
      "displayName": "Kaicheng Ding",
      "photoUrl": "",
      "userId": "10577885083990106787"
     },
     "user_tz": 300
    },
    "id": "bXcLoOVe9Z60",
    "outputId": "e84c0fea-4def-4e94-85fa-d4499927a783"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07"
      ]
     },
     "execution_count": 93,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cVZlC3kK9eKI"
   },
   "outputs": [],
   "source": [
    "model0 = VGG16()\n",
    "model_data = torch.load('gdrive/My Drive/IDL_Project/Model_0')\n",
    "model0.load_state_dict(model_data['model_state_dict'])\n",
    "model0.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 72521,
     "status": "ok",
     "timestamp": 1604458316541,
     "user": {
      "displayName": "Kaicheng Ding",
      "photoUrl": "",
      "userId": "10577885083990106787"
     },
     "user_tz": 300
    },
    "id": "E61q4liOKBlq",
    "outputId": "45686bcb-ab24-40c5-f9cd-22b3c2bc13d6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-04 02:51:57,260 INFO Testing Loss: 0.3685084188319378\n",
      "2020-11-04 02:51:57,261 INFO Testing Accuracy: 88.17%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3685084188319378, 88.17)"
      ]
     },
     "execution_count": 78,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model=model0, test_loader=testloader, criterion=criterion)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "6sToFoYRfKq0"
   ],
   "machine_shape": "hm",
   "name": "idl_project_ensemble.ipynb",
   "provenance": [
    {
     "file_id": "1kP-knBM1cUhCgP3Z39UrCXPaL_g6CLbu",
     "timestamp": 1604177816859
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p36)",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
